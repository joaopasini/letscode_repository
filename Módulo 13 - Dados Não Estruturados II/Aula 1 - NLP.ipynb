{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2HFkxmHfd_R"
   },
   "source": [
    "## Aula 1 - Processamento de Linguagem Natual\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes t√≥picos em Python:\n",
    "\n",
    "1) Dados Estruturados e N√£o Estruturados.  \n",
    "2) Introdu√ß√£o a NLP.  \n",
    "3) Processamento de Textos.  \n",
    "4) Exerc√≠cios.  \n",
    "\n",
    "<img src=\"https://i1.wp.com/thedatascientist.com/wp-content/uploads/2018/09/data_science_wordcloud.png?fit=1584%2C1008&ssl=1\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hgvh29EJh6UK"
   },
   "source": [
    "Primeiramente, precisamos entender qual a diferen√ßa enre as duas fontes de dados mais comuns, sendo elas dados **estruturados** e **n√£o estruturados**. Definimos ele como:\n",
    "<br><br>\n",
    "- **Dados Estruturados:** S√£o dados que seguem uma estrutura mais r√≠gida com um padr√£o fixo e constante. Por exemplo: Tabelas e DataFrames;<br><br>\n",
    "- **Dados N√£o estruturados:** Como j√° diz o nome, s√£o dados que n√£o tem uma estrutura bem estabelecida e necessitam de um processamento adicional para trabalharmos com eles. Exemplos: √°udios, v√≠deos, textos e etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whQI1eePiJwx"
   },
   "source": [
    "### Introdu√ß√£o ao Processamento de Linguagem Natural (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwjo0xx9h-Pi"
   },
   "source": [
    "O Processamento de Linguagem Natural, mas conhecido como NLP, √© a abordagem onde trabalhamos com **dados n√£o estruturados** do tipo **Texto**. O objetivo de trabalharmos com textos √© extrair de informa√ß√£o e teor lingu√≠stico das nossas bases de textos e converter isso de uma forma n√∫merica, onde poderemos utilizar em nossos modelos de *Machine Learning*.<br><br>\n",
    "Temos como exemplos de aplica√ß√µes de NLP como:\n",
    "- An√°lise de Sentimentos em review de filmes e produtos ou mensagens em redes sociais;\n",
    "- Filtro de E-Mails Spams e N√£o Spams;\n",
    "- Identifica√ß√£o de textos a partir de constru√ß√µes lingu√≠sticas (descobrir se um texto foi escrito ou n√£o por Machado de assis);\n",
    "- Tradutores de Idiomas;\n",
    "- ChatBots;\n",
    "- Corretores Ortogr√°ficos;\n",
    "- Classifica√ß√£o de textos de acordo com o conte√∫do do texto (Esportes, Pol√≠tica, Economia e etc).\n",
    "<br><br>\n",
    "Nesta aula iremos aprender a partir dos nossos dados textuais a como processar, tratar e transformar os dados de uma maneira que os modelos de *Machine Learning* entendam.<br><br>\n",
    "\n",
    "A principal biblioteca de refer√™ncia para NLP chama-se [NLTK - Natural Language Toll Kit](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsI5e-Sjn_U1"
   },
   "source": [
    "**Drops** \n",
    "\n",
    "Procure outras aplica√ß√µes de NLP, pode ser na √°rea que trabalha!\n",
    "\n",
    "Por exemplo, na √°rea financeira\n",
    "____\n",
    "R:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjXHV5QOjWDc"
   },
   "source": [
    "### Processamento de Textos\n",
    "\n",
    "Antes de mais nada, precisamos filtrar e tratar os nossos textos, de forma a deixar apenas o conte√∫do de mais relevantes para a nossa an√°lise. Existem alguns processos importantes para trabalhar com os textos (n√£o necessariamente voc√™ precisa aplicar todos os procesos)\n",
    "\n",
    "- Remo√ß√£o de Stopwords;\n",
    "- Limpeza de Textos;\n",
    "- Tokeniza√ß√£o;\n",
    "- Normaliza√ß√£o do Texto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3IR-pN2DjwXJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joao_pasinihotmail/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joao_pasinihotmail/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/joao_pasinihotmail/nltk_data...\n",
      "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importanto o NLTK\n",
    "import nltk\n",
    "# Importando o stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Fazendo o download das stopwords do nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') # https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n",
    "nltk.download('rslp')  # Stemmer para portugu√™s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9je2oXCjjrwc"
   },
   "source": [
    "### Stopwords\n",
    "\n",
    "Stopwords s√£o palavras que aparecem com uma frequ√™ncia muito alta nos textos, mas que n√£o trazem um teor de conte√∫do relevante para o nosso modelo. Vamos entender isso na pr√°tica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR2RHfCOn83i"
   },
   "source": [
    "Baixada a fun√ß√£o de Stopwords, vamos definir um set de stopwords onde teremos uma lista com todas as stopwords em ingl√™s j√° identificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-t93Bq2FncDC"
   },
   "outputs": [],
   "source": [
    "stopwords_port = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LllQ0D8sol9G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " '√†',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " '√†s',\n",
       " 'at√©',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " '√©',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " '√©ramos',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'est√°',\n",
       " 'estamos',\n",
       " 'est√£o',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'est√°vamos',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiv√©ramos',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estiv√©ssemos',\n",
       " 'estou',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'f√¥ramos',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'f√¥ssemos',\n",
       " 'fui',\n",
       " 'h√°',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'h√£o',\n",
       " 'havemos',\n",
       " 'haver',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houver√°',\n",
       " 'houveram',\n",
       " 'houv√©ramos',\n",
       " 'houver√£o',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houver√≠amos',\n",
       " 'houvermos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houv√©ssemos',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'j√°',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'n√£o',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'n√≥s',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 's√£o',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'ser',\n",
       " 'ser√°',\n",
       " 'ser√£o',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'ser√≠amos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 's√≥',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'tamb√©m',\n",
       " 'te',\n",
       " 'tem',\n",
       " 't√©m',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'ter√°',\n",
       " 'ter√£o',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'ter√≠amos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 't√≠nhamos',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiv√©ramos',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tiv√©ssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'voc√™',\n",
       " 'voc√™s',\n",
       " 'vos']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClhJwZvOoqI-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OEsva3po-FN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcQKI7ZdolbV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-16r_klQolCC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6gP4YowoyYk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyHAf5Uko0ZQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9Dpg-8ApIxa"
   },
   "source": [
    "Vamos agora aplicar a remo√ß√£o de Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvrcEJsQo_tf"
   },
   "outputs": [],
   "source": [
    "example = [\"my\", \"house\", \"is\", \"black\", \"and\", \"white\", \"but\", \"isn't\", \"big\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDF1D4zVpNTK"
   },
   "source": [
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que remova da lista `example` elementos que estejam presentes na lista `stopwords_en`.\n",
    "\n",
    "Nessa fun√ß√£o deve ter tr√™s par√¢metros:\n",
    "- words\n",
    "- stopwords\n",
    "- debug\n",
    "\n",
    "A `words` √© uma lista de palavras, como a vari√°vel `example` criada acima (List[str]).\n",
    "\n",
    "A `stopwords` √© uma lista de palavras de stopwords, como a vari√°vel `stopwords_en` criada acima (List[str]).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, identificando quais palavras/elementos foram removidos durante a limpeza dos dados. Esse par√¢metro √© um boolean (True/False), se verdadeiro iremos imprimir quais palavras foram retiradas.\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUaavlQhtf8g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dApkKy6sJFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAg9BYDItTpx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVe-4PuSpMBQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLUUxouBt20M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqzUgiFkrNSJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuslDstSsCpJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSmVHk8MxHSS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnYz481KOjkM"
   },
   "source": [
    "### Limpeza do Texto\n",
    "\n",
    "Existem alguns cuidados com rela√ß√£o a grafia das palavras e elementos em um texto que devemos tomar bastante cuidado antes de fazer qualquer outra coisa. Esses pontos s√£o:<br><br>\n",
    "- Transformar todas as palavras para MAI√öSCULAS ou min√∫sculas;\n",
    "- Remover caracteres especiais;\n",
    "- Remover d√≠gitos (quando n√£o forem relevantes);\n",
    "- Remover acentua√ß√£o (caso t√≠pico de quando trabalhamos com textos em Portugu√™s);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9xYl3yhOswd"
   },
   "source": [
    "### Converter entre MAI√öSCULA e min√∫scula\n",
    "\n",
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que receba uma palavra e normalizando-as em caixa alta ou baixa.\n",
    "\n",
    "Nessa fun√ß√£o deve ter tr√™s par√¢metros:\n",
    "- word\n",
    "- debug\n",
    "\n",
    "A `word` palavra, como por exemplo `Rel√≥gio` (str).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a palavra antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg4DogilOgcG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4kz-e3tSjuO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU99j1FMQevr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msC_BxNLR1NX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSt1MM8IU8Y1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQH1sefETv53"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY70APJHWcne"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHQuk4TRU-Wd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYRTjdWiTKWu"
   },
   "source": [
    "### Remo√ß√£o de d√≠gitos, caracteres especiais e qualquer outro item que n√£o queremos no texto\n",
    "\n",
    "Para essa etapa do processo, iremos utilizar uma biblioteca auxiliar [RegEx (Regular Expression)](https://docs.python.org/3/library/re.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iE4HC6guTNGR"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n2D1Od-TVVx"
   },
   "source": [
    "Importada a biblioteca, vamos utilizar a fun√ß√£o *re.sub*, para substituir os elementos que n√£o queremos nos nossos textos:\n",
    "\n",
    "**Procure por re.sub**  \n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "\n",
    "#### Removendo digitos\n",
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que receba uma frase e remova os digitos ([0-9]).  \n",
    "Nessa fun√ß√£o deve ter dois par√¢metros:\n",
    "- phrase\n",
    "- debug\n",
    "\n",
    "A `phrase`, √© uma frase como por exemplo `'Siga nas redes sociais o @letscode, ja somos mais de 1 milhao de #hashtags e 200 mil followers'` (str).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a frase antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo.\n",
    "\n",
    "Obs: Utilize o site https://regex101.com/ para criar o regex e o re.sub para substituir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ2RZpGGTSSn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIdEff7aWkw1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K7Ns8chXW2I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoklF4g7XvM-"
   },
   "outputs": [],
   "source": [
    "frase = 'Siga nas redes sociais o @letscode, ja somos mais de 1 milhao de #hashtags e 200 mil followers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKrLqy3bX1k0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecSQLsU9X3SC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HcZ7XmNYAM_"
   },
   "source": [
    "#### Removendo caracteres especiais\n",
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que receba uma frase e remova os caracteres especiais (p.ex, √£,√µ, √™, @, #, etc).  \n",
    "Nessa fun√ß√£o deve ter dois par√¢metros:\n",
    "- phrase\n",
    "- debug\n",
    "\n",
    "A `phrase`, √© uma frase como por exemplo `'Siga nas redes sociais o @letscode, ja somos mais de 1 milhao de #hashtags e 200 mil followers'` (str).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a frase antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo.\n",
    "\n",
    "Obs: Utilize o site https://regex101.com/ para criar o regex e o re.sub para substituir.\n",
    "\n",
    "Obs2: Procure por alfanum√©rico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYiu-XQDYmfd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Urf2soY948"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVdBXrGVZLHB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMxkvL3FZO08"
   },
   "outputs": [],
   "source": [
    "remove_special_char(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwc6j-dzZsXP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuqfqkjuabuH"
   },
   "source": [
    "Utilizem a documenta√ß√£o para descobrir mais c√≥digos para filtrar elementos ou mesmo deem uma olhada nesse artigo, que resume de uma forma bem visual as aplica√ß√µes do RegEx: [clique aqui](https://amitness.com/regex/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeoTPv_4agE2"
   },
   "source": [
    "Hoje os emojis fazem parte da comunica√ß√£o via mensagens, por isso iremos ver como utilizar frases contento emojis e trata-los de forma adequada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Twyme__7afbF"
   },
   "outputs": [],
   "source": [
    "# Iremos utilizar a biblioteca emoji\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCZwZhJLaTnj"
   },
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb4EGxBSatqv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcRH6cAZbONN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9HCV1QKbjXG"
   },
   "source": [
    "Para ver a lista completa:\n",
    "\n",
    "https://www.webfx.com/tools/emoji-cheat-sheet/\n",
    "\n",
    "Link biblioteca: https://github.com/carpedm20/emoji/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7ZrPwFqb7KC"
   },
   "source": [
    "#### Convertendo emojis para texto\n",
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que receba uma frase e converta os emojis para texto\n",
    "Nessa fun√ß√£o deve ter dois par√¢metros:\n",
    "- phrase\n",
    "- debug\n",
    "\n",
    "A `phrase`, √© uma frase como por exemplo `Python is üëç` (str).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a frase antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Gf3OP6WbrFU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orI4UsErcU4h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1RYVu_5dBHH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caQR5XL1dCzs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZap5orRdLUE"
   },
   "source": [
    "Agora que vimos diversas fun√ß√µes e tratamentos, podemos utilizar o regex para valida√ß√£o de e-mail, por exemplo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftT89PXndWFh"
   },
   "source": [
    "#### Crie uma fun√ß√£o que receba uma string e valide se √© poss√≠velmente um e-mail\n",
    "**Drops**\n",
    "\n",
    "Crie uma fun√ß√£o que receba um email e verifique se √© um formato v√°lido de e-mail\n",
    "- email\n",
    "- debug\n",
    "\n",
    "A `email`, √© uma frase como por exemplo `myemail@gmail.com` (str).\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a frase antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CilxbjvAdSxl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtubRPQHey_z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMQ9SchZe1Lf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlxzMtefggjm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMf6iNGAf89I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae80wZOIgtyP"
   },
   "source": [
    "Aplica√ß√£o de NLP para valida√ß√£o de campos.  \n",
    "- Muito √∫til para evitar ataques de baixa qualidade \n",
    "- Evitar cadastro de pessoas inv√°lidas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laoYA1wYg6Yj"
   },
   "source": [
    "Podemos utilizar NLP para identificar frases que contenham uma palavra chave!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMWmNH37gQCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWTvxMBQhB-G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5f4aJfl7QCC"
   },
   "source": [
    "### Remo√ß√£o de Acentua√ß√£o\n",
    "Para a remo√ß√£o de acentua√ß√£o, iremos utilizar uma bibloteca chamada *Unidecode*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7hpJwTa7SIY"
   },
   "outputs": [],
   "source": [
    "# Caso precise instalar a biblioteca, descomente o c√≥digo abaixo\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eLSKg7A7TS5"
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFxZKdkJ7VHI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XinjRSkG7ZPB"
   },
   "source": [
    "**Drops**\n",
    "\n",
    "Que remova a acentua√ß√£o das palavras de uma frase\n",
    "- phrase\n",
    "- debug\n",
    "\n",
    "A `phrase`, √© uma frase como por exemplo 'Jo√£o Sebasti√£o Alvar√° Vov√¥ Lingui√ßa express√£o'.\n",
    "\n",
    "O par√¢metro `debug` ir√° auxiliar no debug, podendo imprimir a frase antes e ap√≥s a transforma√ß√£o\n",
    "\n",
    "**Extra:**\n",
    "\n",
    "Comumente utilizamos TDD (test driven development).\n",
    "\n",
    "Portanto crie um teste para essa fun√ß√£o para garantir a qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD3UOkNu7WqD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQg499Zr8auG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtMjFbA-8pHa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbHMYcx38qek"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhV4Z2xB89HI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcoeEmpC9Kbc"
   },
   "source": [
    "## Tokeniza√ß√£o\n",
    "\n",
    "Tokeniza√ß√£o √© um processo onde transformamos um texto de uma string √∫nica em fragmentos desse texto na forma de *tokens*, que nada mais s√£o do que as pr√≥prias palavras! Para isso, vamos utilizar a fun√ß√£o *word_tokenize* do NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucLVo_6j9L9x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOwuFw8Q9O2s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcgxYEK19PjP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qed6o8G9Vib"
   },
   "source": [
    "## Normaliza√ß√£o de Textos\n",
    "\n",
    "**Normaliza√ß√£o de Textos (Text Normalization)** √© o procedimento que consiste em **padronizar** o texto, de modo a evitar que varia√ß√µes tornem os modelos demasiadamente complexos. Por exemplo: tratar singular/plural como a mesma coisa, ou ent√£o eliminar conjuga√ß√£o de verbos. Outras componentes comuns da normaliza√ß√£o s√£o a de eliminar palavras que n√£o agregam muito significado, ou palavras muito raras.\n",
    "\n",
    "Abaixo alguns exemplos de a√ß√µes de Text Normalization que podem ser aplicadas no pr√©-processamento de dados textuais:\n",
    "\n",
    "**Stemming** - Redu√ß√£o de tokens √† sua raiz invariante atrav√©s da **remo√ß√£o de prefixos ou sufixos**. Baseado em heur√≠stica<br>\n",
    "**Lemmatization** - Redu√ß√£o de tokens √† sua raiz invariante atrav√©s da **an√°lise lingu√≠stica do token**. Baseado em dicion√°rio l√©xico<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieG5enJ79aUg"
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA-tVw5S9RGm"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TLZDxkF9l8r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSZhPhGP9cqF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jf0ggw2I9qFx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7Ee5lvk9gK9"
   },
   "source": [
    "## Lemmatization\n",
    "\n",
    "Obs: N√£o funciona para portugu√™s, precisamos utilizar o Spacy (outra biblioteca para NLP), veremos mais adiante no curso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnQrtAl_9d_n"
   },
   "outputs": [],
   "source": [
    "# Importando o Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# https://www.nltk.org/howto/wordnet.html\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# NLTK 3.6.6 release: December 2021:\n",
    "# support OMW 1.4, use Multilingual Wordnet Data from OMW with newer Wordnet versions\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-bLgWtE_Xpc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaqVvMR-_cfF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4j3dnhJ_d1n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UihVRxqc_0Co"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxH2uhI4A8mq"
   },
   "source": [
    "## Pipeline de Processamento de Textos\n",
    "\n",
    "Conhecendo todos os tipos de processamentos que podemos utilizar, uma forma √∫til e organizada para isso √© construirmos uma fun√ß√£i que receba o nosso dados originais e realizada todos os processamentos que queremos nos textos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4qLqa46BBUi"
   },
   "source": [
    "**drops**\n",
    "\n",
    "Crie uma classe que seja capaz de:\n",
    "\n",
    "- Metodo para remover acentua√ß√£o\n",
    "- Metodo de remover digitos\n",
    "- Metodo de remover caracteres especiais\n",
    "- Metodo de normalizar o texto em caixa baixa\n",
    "- Metodo para criar os tokens\n",
    "- Metodo para filtrar stopwords\n",
    "- Metodo para pegar o stemming\n",
    "- Metodo para pegar o lemma\n",
    "- Metodo de pipeline.\n",
    "\n",
    "Obs: N√£o iremos fazer os testes em classe, mas √© um desafio interessante de ser realizado p√≥s-aula para treinar TDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQSRgAlFAAnB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brOZjdj3Cp96"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsFClqwMHbvb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDWoIbbJHfKz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq1dJuERHw7_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWOcLEWiH8yA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfFVnJPxIDvj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkU2HCMLILSn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhKiVPx5IiLf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PACJIBDJJ3O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJB5z7LpJTMB"
   },
   "source": [
    "Vamos agora j√° come√ßar a pr√°ticar com os nossos dados de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8gBYe6iJPcL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF2sg0DYJRRK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fe4sNUVJiKT"
   },
   "source": [
    "Nosso exemplo ser√° uma An√°lise de Sentimento em Cr√≠ticas de Filmes, onde vamos identificar se a cr√≠tica foi boa ou n√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVkn3PA9JfJ5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBt2MOmoJlAK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGJi_cyTJmSP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egXSFU8wJokk"
   },
   "source": [
    "A nossa base de dados tem 50 mil linhas e levando em considera√ß√£o que as cr√≠ticas s√£o sobre filmes diversos, a quantidade de palavras dispon√≠veis nos textos ser√° muito grande. Para economizar tempo de aula com processamneto dos textos e modelagem, iremos criar uma amostra com 10% da base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjNnxvhNJpHa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQ5c0kNVJr62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E39T4pD8Jttk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up0Jq5VjJxOE"
   },
   "source": [
    "Agora iremos aplicar o nosso processamento dos textos:\n",
    "\n",
    "**Drops**\n",
    "\n",
    "Aplique o pipeline acima da classe `PreProcesssPhrase()`\n",
    "```\n",
    "pipeline = [\n",
    "    'remove_digits',\n",
    "    'remove_special_char',\n",
    "    'word_lower',\n",
    "    'tokenizer',\n",
    "    'remove_stopwords',\n",
    "    'stemmer'\n",
    "]\n",
    "```\n",
    "\n",
    "Na base de dados movies, coluna `text`, atribua o resultado numa coluna chamada `filtered_words`\n",
    "\n",
    "Obs: pode ser utilizado o apply para tal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRq2rK6zJtq7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZ2c4TInLOrq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BloPLguAJtoE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWQEv92ALVPk"
   },
   "source": [
    "## Corpus\n",
    "\n",
    "Com isso chegamos ao fim do pr√©-processamento, uma das etapas mais importantes de todo projeto de NLP!\n",
    "\n",
    "√â importante ressaltar que a escolha das etapas de pr√©-processamento n√£o √© algo √≥bvio, dado que h√° muitas escolhas poss√≠veis acerca do que se fazer para pr√©-processar os dados. Assim, o indicado √© treinar diferentes modelos testando diferentes combina√ß√µes das t√©cnicas de pr√©-processamento, at√© que o melhor procedimento seja encontrado!\n",
    "\n",
    "**Nomenclatura**: o conjunto de mensagens (tamb√©m conhecido como documentos) pr√©-processadas √© chamado de **Corpus**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugfwM9cOLYts"
   },
   "source": [
    "## Vocabul√°rio\n",
    "\n",
    "O vocabul√°rio do corpus nada mais √© do que uma listagem das palavras individuais que aparecem no corpus. Para encontrar o vocabul√°rio, basta contarmos a apari√ß√£o de cada palavra isolada no corpus. Ao fim, teremos N palavras √∫nicas que comp√µem nosso vocabul√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwwjo0QzJtlM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zi-hdDGVJtid"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaDYDJLkJtfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4G1jkmlgLl5r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZ0eJb_JLmUX"
   },
   "source": [
    "### Criando nossa nuvem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z8aqO6eJtck"
   },
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3G_skT-JtU_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvelnSM4LrNE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrGD0nDYLrJr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKO6pDTTMDWl"
   },
   "source": [
    "**Vocabul√°rio de cr√≠ticas positivas**\n",
    "\n",
    "Criando a wordcloud apenas de cr√≠ticas positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma7-FGpoLrDb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmoFx5dlML9X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiIS-XMEMO3W"
   },
   "source": [
    "**Vocabul√°rio de cr√≠ticas negativas**\n",
    "\n",
    "Criando a wordcloud apenas de cr√≠ticas negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MJPp941ML6l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf66OnpYMVSL"
   },
   "source": [
    "## Exerc√≠cios\n",
    "\n",
    "**1)** Usando a base *spamraw.csv*, fa√ßa o processamento dos textos aplicando as limpezas necess√°rias para tal. Tente levantar o vocabul√°rio dos e-mails e imprima o top 10 palavras deste dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClHbN5ezMUti"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLfthU86MggL"
   },
   "source": [
    "**2)** Utilizando os dados de tweets vamos avaliar  tweets s√£o de desastres ou n√£o. Essa base √© um dataset conhecido do Kaggle, onde voc√™s podem ter mais detalhes [clicando aqui](https://www.kaggle.com/c/nlp-getting-started/overview). Fa√ßa o processamento dos textos aplicando as limpezas necess√°rias para tal. Tente levantar o vocabul√°rio dos e-mails e print o top 10 palavras deste dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOfCHWPENHWc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 1 - NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
