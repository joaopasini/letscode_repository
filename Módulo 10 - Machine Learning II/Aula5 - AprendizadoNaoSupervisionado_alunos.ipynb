{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4 - Aprendizagem Não-Supervisionada\n",
    "\n",
    "Na aula de hoje, vamos mudar um pouco a nossa abordagem sobre modelos de aprendizado e conversar sobre os seguintes tópicos:\n",
    "\n",
    "- 1. Aprendizagem não-supervisionada\n",
    "- 2. Exemplos de modelos não supervisionados\n",
    "- 3. Principais métricas de desempenho de um modelo supervisionado\n",
    "- 4. Realização de um estudo de caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aprendizado Não-Supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de aprendizagem se diferencia da aprendizagem supervisionada de modo muito simples: **os targets não fazem parte da base de dados!**\n",
    "\n",
    "> Na aprendizagem não-supervisionada, temos acesso apenas ao conjunto de features, $\\{\\vec{x}_i\\}_{i=1}^N$\n",
    "\n",
    "A perda que temos com relação à aprendizagem supervisionada é gigante: sem os targets, torna-se impossível a estimação do processo teórico $\\mathcal{F}$ que gerou os dados!\n",
    "\n",
    "Assim, o máximo que podemos fazer na aprendizagem não-supervisionada é a **determinação de estrutura nos dados**:\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Zhenyu-Wen-2/publication/336642133/figure/fig3/AS:815304842170368@1571395230317/Examples-of-Supervised-Learning-Linear-Regression-and-Unsupervised-Learning.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um problema de classificação, somos capazes de encontrar a fronteira de decisão dentre as classes que **são conhecidas no treino**:\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/f29c8ebf-dd5f-4fce-99bb-86ec8af21f51.PNG width=700>\n",
    "\n",
    "Já em com dados não-supervisionados, o máximo que podemos fazer é encontrar a estrutura presente nos dados (e com maior dificuldade!)\n",
    "\n",
    "<img src=https://s3-sa-east-1.amazonaws.com/lcpi/0c7b530d-e74b-4886-9601-740d054aa166.PNG width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para muitas aplicações, isso já é suficiente: basta saber que os dados estão estruturados (agrupados/segmentados), sendo o significado de cada grupo/segmento de menor interesse, ou facilmente estimado de outra forma; ou, então, determinar aspectos importantes das features por si só, sem qualquer preocupação com o target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exemplos de Modelos Não-Supervisionados \n",
    "\n",
    "- **Clusterização** - forma de encontrar grupos (clusters) nos dados por meio da comparação de métricas de similaridade, geralmente sendo métricas de \"distâncias\" em relação de cada ponto em relação ou em relação a uma referência\n",
    "  - KMeans\n",
    "  - KMedoids ou KMedians\n",
    "  - Clusterização Hierárquica\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1838/1*S_Pkf-cK1gUE0OPbDM81ww.png\">\n",
    "\n",
    "- **Modelos de Densidade** - também é uma forma de agrupamento, porém são mais relacionados à densidade dos pontos numa determinada região do espaço. Geralmente tem uma abordagem probabilística.\n",
    "  - DBSCAN\n",
    "  - Modelos de Mistura Gaussiana\n",
    "- **Redução de dimensionalidade** - importante processo de pré-processamento que visa reduzir o número de dimensões (features) de um dataset. Ao contrário da seleção explítica de atributos, a redução de dimensionalidade atua aplicando uma transformação algébrica na forma de uma combinação dos atributos originais em dimensões menores.\n",
    "  - PCA\n",
    "  - Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Principais Métricas para Modelos Não Supervisionados - Foco em Clusterização\n",
    "\n",
    "Um resumo completo de métricas de algoritmos não supervisionados pode ser encontrado na [página do scikit-learn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Vamos falar das principais.\n",
    "\n",
    "### Score de Silhueta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **score da silhueta** é uma medida de similaridade de um registro em relação ao seu próprio *cluster* (também conhecido como *coesão*) quando comparado a outros clusters (conhecido como separação). É um valor que varia de -1 a +1, onde valores grandes e positivos apontam que o registro está bem agrupado no cluster apontado e que ele não se adequa bem a nenhum outro cluster vizinho.\n",
    "\n",
    "Se a grande maior dos scores de silhueta são positivos, então dizemos que a configuração dos agrupamentos é adequada.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/AI/67.PNG\">\n",
    "\n",
    "A definição do score de silhueta é:\n",
    "\n",
    "$$s(i) = \\frac{b(i) - a(i)}{\\max{[a(i), b(i)]}}$$\n",
    "\n",
    "Onde $a(i)$ é a distância média do ponto $i$ até todos os pontos **pertencentes ao mesmo cluster ao qual i foi atribuído**; b(i) é a menor distância do ponto $i$ até os pontos dos **outros clusters que não são os mesmos ao qual $i$ foi atribuído**\n",
    "\n",
    "Mais informações sobre o score de silhueta podem ser encontrados [nesse link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html#sklearn.metrics.silhouette_samples) e [nesse link](https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneidade, Complitude e V-Score\n",
    "\n",
    "Pode acontecer de usarmos as métricas de clusterização para descobrir estruturas de interesse, mesmo quando conhecemos os rótulos dos dados.\n",
    "\n",
    "Nesse caso, estamos mais interessados em entender as similaridades dos atributos dos registros pertencentes a cada classe do que em classificar os registros propriamente ditos.\n",
    "\n",
    "A métrica de **homogeneidade** nos diz se cada agrupamento ou cluster contém apenas elementos de uma mesma classe conhecida. É uma forma de analisar a \"pureza\" da distribuição *intra-cluster*\n",
    "\n",
    "A métrica de **complitude** nos diz se todos os membros de uma determinada classe foram atribuídos ao mesmo cluster. Nesse caso, estamos analisando a distribuição *inter-cluster*.\n",
    "\n",
    "A métrica do **V-score** é a média harmônica da homogeneidade e da complitude.\n",
    "\n",
    "$$v=\\frac{(1+\\beta)\\times h \\times c}{\\beta h + c}$$\n",
    "\n",
    "Onde: $\\beta$ controla a importância do atributo complitude.\n",
    "\n",
    "Mais detalhes podem ser vistos [nesse link](https://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "**Exercício 1**\n",
    "\n",
    "Utilizando a mesma estratégia desenvolvida no exemplo, faça uma análise comparativa dos agrupamentos de clientes do banco (dataset *german_credit_data.csv*) separando-os em 3, 4 e 5 agrupamentos. Quais são as variáveis que mais apresentação distinções em cada caso?\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
