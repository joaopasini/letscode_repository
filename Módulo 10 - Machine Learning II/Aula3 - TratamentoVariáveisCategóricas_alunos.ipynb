{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3 - Tratamento de Dados Categóricos\n",
    "\n",
    "Na aula de hoje, vamos conversar um pouco sobre:\n",
    "\n",
    "- 1. Codificação de variáveis categóricas\n",
    "- 2. Label Encoding\n",
    "- 3. OneHot Encoding\n",
    "- 4. ColumnTransformer e FunctionTransformer\n",
    "- 5. Target Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Codificação de Variáveis Categóricas\n",
    "\n",
    "A grande maioria dos modelos Machine Learning são implementações de equações matemáticas, teoremas e relações de álgebra linear (lembrem-se do SVM!). Sendo assim, as implementações não estão preparadas para lidar com dados que são representados na forma de texto, como por exemplo, variáveis categóricas, sejam elas ordinais (quando existe uma **naturalmente** hierarquia do que é melhor e do que é pior) ou sejam elas nominais (não se sabe *a priori* se uma categoria é melhor ou pior que outras, pois essa inferência só pode ser feita dos dados amostrados.). Já vimos que existem muitas fontes de dados, e diferentes tipos de variáveis que podem ser extraídas dessas fontes, de forma que nós devemos ter adaptações para lidar com esses obstáculos.\n",
    "\n",
    "<img src=\"https://1.bp.blogspot.com/-5Q-8Bp0BEdY/XhaKPxDvvFI/AAAAAAAAAmE/ZtURz0WKVCsBZsLhXT_TlEFar6g1CnDHgCLcBGAsYHQ/s1600/1.JPG\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim sendo, a técnica mais simples de transformação dos dados textuais em dados é conhecida como *Categorical Encoding*. Existem muitas outras técnicas de transformação de dados textuais, bem mais avançadas e que inclusive podem levar em consideração o sentido semântico da palavra, mas nessa aula vamos nos ater às técnicas mais simples. Em **Dados Não Estruturados**, vocês verão que existe um campo inteiramente dedicado a esse estudo, conhecido como *Natural Language Processing*.\n",
    "Também é importante mencionar que nem todos os algoritmos demandam necessariamente a aplicação de codificação. Árvores de decisão e modelos em árvore, em geral, conseguem trabalhar com atributos codificados em textos.\n",
    "\n",
    "<img src=\"https://mlfromscratch.com/content/images/2020/09/exercise_3-1.png\" width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *Label Encoding* é a técnica mais simples de se realizar codificação de variáveis categóricas. Essencialmente funciona atribuindo simplesmente os valores numéricos para cada valor único da categoria encontrada\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/772/1*QQe-4476Oy3_dI1vhb3dDg.png\">\n",
    "\n",
    "No Python, implementamos o *label enconding* utilizando a classe `LabelEncoder` da biblioteca `scikit-learn`, cuja documentação pode ser encontrada [nesse link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). O `LabelEncoder` faz a identificação das categorias únicas num vetor de dados, ordena-as em ordem crescente e depois atribui os números na ordem que elas aparecem no vetor ordenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, \\\n",
    "    FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "# ignorar warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city     \n",
       "Barcelona    15\n",
       "Paris        13\n",
       "SaoPaulo     12\n",
       "Miami        10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando um vetor base\n",
    "base = ['Miami', 'SaoPaulo', 'Barcelona', 'Paris']\n",
    "\n",
    "# criando um dataframe de múltiplas amostras\n",
    "categories = pd.DataFrame(np.random.choice(base, 50), columns=['city'])\n",
    "\n",
    "# checando distribuições iniciais\n",
    "categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Identificadas:  ['Barcelona' 'Miami' 'Paris' 'SaoPaulo']\n"
     ]
    }
   ],
   "source": [
    "# aplicando o Label Encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(categories.city)\n",
    "\n",
    "# visualizando as classes identificadas\n",
    "print('Classes Identificadas: ', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "2    13\n",
       "3    12\n",
       "1    10\n",
       "Name: city_le, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizando a transformação de colunas\n",
    "categories['city_le'] = le.transform(categories.city)\n",
    "\n",
    "# checando a distribuição das classes codificadas\n",
    "categories.city_le.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_cod</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>SaoPaulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>SaoPaulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>SaoPaulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>SaoPaulo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_cod       city\n",
       "0         1      Miami\n",
       "1         1      Miami\n",
       "2         0  Barcelona\n",
       "3         2      Paris\n",
       "4         3   SaoPaulo\n",
       "5         1      Miami\n",
       "6         3   SaoPaulo\n",
       "7         3   SaoPaulo\n",
       "8         0  Barcelona\n",
       "9         3   SaoPaulo"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# podemos querer recuperar as informações das categorias (para outros dados de teste)\n",
    "city_test = pd.DataFrame(np.random.choice(list(range(4)), 20), columns=['city_cod'])\n",
    "\n",
    "# aplicando a transformada inversa\n",
    "city_test['city'] = le.inverse_transform(city_test.city_cod)\n",
    "\n",
    "city_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">No entanto, o uso do `LabelEncoder` deve ser feito com muito cuidado !!!</font>. Pensemos por um momento da implicação de simplesmente atribuir números às categorias. Fazendo dessa forma, o modelo pode receber a informação de que uma categoria é melhor que outra, simplesmente pelo fato da primeira ter recebido um valor maior que a segunda no Label Encoding. Isso é conhecido como *inferência a priori*, que significa quando o modelador inclui um conhecimento ou um viés previamente à modelagem e, portanto, o modelo terá seus parâmetros ajustados assumindo as premissas como verdadeiras. Por isso, cuidado é necessário nessa transformação.\n",
    "Há casos em que a inferência *a priori* ajuda o treinamento e simplificação dos modelos. Além disso, há casos em que a simples numeração das variáveis não apresenta problema, por exemplo, quando **já existe uma hierarquia** - variáveis categóricas ordinais (\"Bom\", \"Ruim\", entre outros). Aplicar transformações de label encoding na variável alvo (problemas de classificação) também não tem problema.\n",
    "\n",
    "Mas e como proceder nos casos de variáveis preditoras sem hierarquia prévia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One Hot Encoding\n",
    "\n",
    "A técnica de *One Hot Encoding* vem como uma possibilidade de solução para o problema de inferência a priori causada pela aplicação do label encoding. Essencialmente, o one-hot-encoding funciona como a transformação de uma única coluna categórica em múltiplas colunas binárias. Serão criadas tantas colunas quantas forem as classes da variável categórica.\n",
    "\n",
    "<img src=\"https://images.deepai.org/glossary-terms/a609ab3c23f948f896657e4304b20ed1/onehot.jpeg\">\n",
    "\n",
    "Dessa forma, todas as variáveis categóricas são transformadas em valores binárias, que atuam como se fossem \"flags\" indicativas da *presença ou ausência* de cada categoria naquele registro. Dessa forma, avalia-se o efeito de forma mais justa, sem colocar viés no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando o One Hot Encoding no conjunto de dados das cidades\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(categories[['city']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias analisadas: [array(['Barcelona', 'Miami', 'Paris', 'SaoPaulo'], dtype=object)]\n",
      "Novas colunas:  ['city_Barcelona', 'city_Miami', 'city_Paris', 'city_SaoPaulo']\n"
     ]
    }
   ],
   "source": [
    "# analisando categorias e criando novas colunas\n",
    "print('Categorias analisadas:', ohe.categories_)\n",
    "\n",
    "new_cols = [f'city_{col}' for col in ohe.categories_[0]]\n",
    "print('Novas colunas: ', new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_le</th>\n",
       "      <th>city_Barcelona</th>\n",
       "      <th>city_Miami</th>\n",
       "      <th>city_Paris</th>\n",
       "      <th>city_SaoPaulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SaoPaulo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SaoPaulo</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miami</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miami</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paris</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Miami</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Paris</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paris</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  city_le  city_Barcelona  city_Miami  city_Paris  city_SaoPaulo\n",
       "0   SaoPaulo        3             0.0         0.0         0.0            1.0\n",
       "1   SaoPaulo        3             0.0         0.0         0.0            1.0\n",
       "2      Miami        1             0.0         1.0         0.0            0.0\n",
       "3      Miami        1             0.0         1.0         0.0            0.0\n",
       "4  Barcelona        0             1.0         0.0         0.0            0.0\n",
       "5      Paris        2             0.0         0.0         1.0            0.0\n",
       "6      Miami        1             0.0         1.0         0.0            0.0\n",
       "7  Barcelona        0             1.0         0.0         0.0            0.0\n",
       "8      Paris        2             0.0         0.0         1.0            0.0\n",
       "9      Paris        2             0.0         0.0         1.0            0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizando transformação das features\n",
    "categories[new_cols] = ohe.transform(categories[['city']]).toarray()\n",
    "categories.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que o label encoding, a classe `OneHotEncoder` também pertence ao pacote `scikit-learn` e sua documentação pode ser encontrada [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
    "\n",
    "No entanto, um outro cuidado precisa ser tomado com relação ao one hot encoder. Se formos pensar na forma que as variáveis ficam dispostas, podemos notar que existe uma correlação perfeita entre todos as colunas criadas, visto que existe um grau de dependência entre as colunas. Isso quer dizer que, se conhecermos o valor de $n-1$ colunas, automaticamente sabemos o valor da outra coluna restante. Isso é chamado de *dummy variable trap* e causa a ocorrência de um viés no modelo, de forma que ele acaba superdimensionando a importância de uma dos atributos, devido à redundância de informação. Sendo assim, no momento de aplicação, deve-se eliminar uma das variáveis.\n",
    "\n",
    "Em termos de impacto na interpretabilidade do modelo, pode-se entender que a variável que for eliminada, será o \"caso-base\" e que, portanto, os efeitos das outras variáveis que permanecerem podem ser interpretadas como o efeito esperando quando \"se muda do caso base para a categoria selecionada\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Column Transformer e FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer) e o [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer) são ferramentas de automação de processamento providas pelo `scikit-learn` que nos ajudam a realizar a transformação do nosso conjunto de dados.\n",
    "\n",
    "O `FunctionTransformer` aplica uma função definida pelo usuário ou um objeto de função nativa (`np.log`), por exemplo, a uma coluna, de forma a aplicar essa função em todas as linhas do conjunto de dados.\n",
    "\n",
    "O `ColumnTransformer` constrói um \"Pipeline\" de funções transformadoras de colunas, de forma a direcionar a transformação adequada para cada tipo de coluna do dataset.\n",
    "\n",
    "Vejamos um exemplo de aplicação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando os dados\n",
    "data = sns.load_dataset('penguins')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando dados nulos\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação de dados preditores e preditos\n",
    "x = data.drop(['species'], axis = 1)\n",
    "y = data[['species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar um transformador de colunas\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        ('one_hot_categ', OneHotEncoder(drop='first'), ['island', 'sex']),\n",
    "        ('log_body_mass', FunctionTransformer(np.log), ['body_mass_g'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação do conjunto treino e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=19)\n",
    "\n",
    "# criando o amostrador \n",
    "cvs = StratifiedKFold(n_splits=10, shuffle=True, random_state=19)\n",
    "\n",
    "# criando o pipeline\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('tree', DecisionTreeClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# criando o dicionário de distribuições\n",
    "param_dict = {\n",
    "    'tree__criterion': ['entropy', 'gini'],\n",
    "    'tree__max_depth': [1, 2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;one_hot_categ&#x27;,\n",
       "                                                                               OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                                               [&#x27;island&#x27;,\n",
       "                                                                                &#x27;sex&#x27;]),\n",
       "                                                                              (&#x27;log_body_mass&#x27;,\n",
       "                                                                               FunctionTransformer(func=&lt;ufunc &#x27;log&#x27;&gt;),\n",
       "                                                                               [&#x27;body_mass_g&#x27;])])),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;tree&#x27;,\n",
       "                                              DecisionTreeClassifier())]),\n",
       "                   param_distributions={&#x27;tree__criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;tree__max_depth&#x27;: [1, 2, 3, 4, 5]},\n",
       "                   random_state=19, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;one_hot_categ&#x27;,\n",
       "                                                                               OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                                               [&#x27;island&#x27;,\n",
       "                                                                                &#x27;sex&#x27;]),\n",
       "                                                                              (&#x27;log_body_mass&#x27;,\n",
       "                                                                               FunctionTransformer(func=&lt;ufunc &#x27;log&#x27;&gt;),\n",
       "                                                                               [&#x27;body_mass_g&#x27;])])),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;tree&#x27;,\n",
       "                                              DecisionTreeClassifier())]),\n",
       "                   param_distributions={&#x27;tree__criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
       "                                        &#x27;tree__max_depth&#x27;: [1, 2, 3, 4, 5]},\n",
       "                   random_state=19, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;one_hot_categ&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;island&#x27;, &#x27;sex&#x27;]),\n",
       "                                                 (&#x27;log_body_mass&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;ufunc &#x27;log&#x27;&gt;),\n",
       "                                                  [&#x27;body_mass_g&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;tree&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;one_hot_categ&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;island&#x27;, &#x27;sex&#x27;]),\n",
       "                                (&#x27;log_body_mass&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;ufunc &#x27;log&#x27;&gt;),\n",
       "                                 [&#x27;body_mass_g&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_categ</label><div class=\"sk-toggleable__content\"><pre>[&#x27;island&#x27;, &#x27;sex&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">log_body_mass</label><div class=\"sk-toggleable__content\"><pre>[&#x27;body_mass_g&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log&#x27;&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('one_hot_categ',\n",
       "                                                                               OneHotEncoder(drop='first'),\n",
       "                                                                               ['island',\n",
       "                                                                                'sex']),\n",
       "                                                                              ('log_body_mass',\n",
       "                                                                               FunctionTransformer(func=<ufunc 'log'>),\n",
       "                                                                               ['body_mass_g'])])),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('tree',\n",
       "                                              DecisionTreeClassifier())]),\n",
       "                   param_distributions={'tree__criterion': ['entropy', 'gini'],\n",
       "                                        'tree__max_depth': [1, 2, 3, 4, 5]},\n",
       "                   random_state=19, scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criar e treinar o seletor de hiperparâmetros\n",
    "hyp_tun = RandomizedSearchCV(pipe,\n",
    "                             param_dict,\n",
    "                             n_iter = 10,\n",
    "                             scoring = 'accuracy',\n",
    "                             refit = True,\n",
    "                             random_state=19)\n",
    "hyp_tun.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros:  {'tree__max_depth': 5, 'tree__criterion': 'entropy'}\n",
      "Melhor acurácia média:  0.9698812019566736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.96      0.90      0.93        29\n",
      "   Chinstrap       0.93      0.93      0.93        14\n",
      "      Gentoo       0.92      1.00      0.96        24\n",
      "\n",
      "    accuracy                           0.94        67\n",
      "   macro avg       0.94      0.94      0.94        67\n",
      "weighted avg       0.94      0.94      0.94        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verificando melhores parâmetros e melhor métrica\n",
    "print('Melhores parâmetros: ', hyp_tun.best_params_)\n",
    "print('Melhor acurácia média: ', hyp_tun.best_score_)\n",
    "\n",
    "# realizando novas predições\n",
    "yhat = hyp_tun.best_estimator_.predict(x_test)\n",
    "\n",
    "# relatório de classificação\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Agora vamos utilizar o pipeline e column-transformer num problema de regressão. Com a base 'Steel_industry_data.csv':\n",
    "\n",
    "- carregue a base\n",
    "- Elimine as seguintes colunas: `Date`\n",
    "- Eliminar dados nulos\n",
    "- Aplique um column transformer nas colunas WeekStatus, Day_of_Week, Load_type\n",
    "- Separar 30 % para teste\n",
    "- Use o Random Search com 5 iterações para selecionar os hiperparâmetros (**Cuidado** com o número de hiperparâmetros pois o conjunto de dados é grande)\n",
    "- Use um objeto `KFold` para validação cruzada (use 3 folds)\n",
    "- As métricas de seleção podem ser o $R^2$ ou o MAE\n",
    "- Teste os modelos `LinearRegression`, e `RandomForest`\n",
    "- Utilize o modelo do `Pipeline`\n",
    "- Não se esqueça de aplicar o escalonamento dos dados (`StandardScaler`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Introdução ao Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em alguns casos, pode acontecer dos conjuntos de dados possuírem colunas com muitas classes (10 ou mais). Se formos aplicar one hot encoding para todas, cada uma dessas colunas vai produzir outras 10 ou mais colunas adicionais, de forma que o conjunto de dados final teria uma altíssima dimensionalidade. Conforme vamos ver lá em ML3, alta dimensionalidade pode ser muito ruim, de forma que o modelo pode facilmente ser *overfittado*. Assim, nesses casos, podemos utilizar uma técnica conhecida como **TargetEncoding**.\n",
    "\n",
    "O Target Encoding é como se fosse uma codificação de variáveis categóricas de uma forma \"supervisionada\", onde usamos informação da variável \"alvo\" para codificar a variável categórica. Sendo assim, é importante realizá-la somente depois da separação treino teste para evitar o **information leakage**. Existe [esse pacote](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) que implementa o Target Encoding numa forma parecida com o `scikit-learn`.\n",
    "\n",
    "Para evitar a explosão dimensional, o Target Encoding subsitui a variável categórica pela média, mediana ou moda da variável alvo considerando somente os registros pertecentes àquela classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1ba8794fa85fbaa82e75e2932815913cb5407855996c12a16cc8e292cbcd9f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
