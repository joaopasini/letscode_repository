{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova módulo - ML1 - Gabarito\n",
    "\n",
    "_____\n",
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\n",
    "\n",
    "Para aferir a capacidade de generalização de um modelo supervisionado, é muito importante que o volume de dados original seja separado nas amostras de treino e de teste. \n",
    "\n",
    "O modelo é treinado utilizando os dados de treino; e os dados de teste são utilizados ao fim do processo, para avaliar sua performance em dados não vistos em treinamento, estimando, assim, sua capacidade de generalização.\n",
    "\n",
    "(x) Verdadeiro\n",
    "\n",
    "( ) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Tudo certo!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\n",
    "\n",
    "Utilizamos uma abordagem data-driven, baseada em aprendizagem de máquina, em problemas tais que:\n",
    "\n",
    "- Existe um padrão a ser descoberto (que assumimos ser o processo teórico $\\mathcal{F}$ que rege o problema);\n",
    "- Uma descrição teórica não é praticável;\n",
    "- Existam dados coletados sobre o problema, isto é, amostras geradas pelo proceso teórico $\\mathcal{F}$.\n",
    "\n",
    "(X) Verdadeiro\n",
    "\n",
    "( ) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Tudo certo!\n",
    "<br><br>\n",
    "Um comentário aqui, pessoal, sobre cada um dos pontos:\n",
    "    \n",
    "- Se não existir nenhum padrão a ser aprendido, mesmo os melhores métodos de aprendizagem não produzirão um bom resultado, afinal, não há o que aprender! E, de fato, isso pode acontecer na vida real, sobretudo se os dados não forem coletados da maneira adequada/não refletirem o processo teórico no qual estamos interessados;<br><br>\n",
    "    \n",
    "- Se tivéssemos uma abordagem teórica, construída a partir de princípios fundamentais, teríamos uma descrição perfeita do problema sob análise, certo? Neste caso, não precisaríamos fazer modelos de Machine Learning, que por mais que funcionem bem, sempre terão erros associados. Acontece que é qause sempre impraticável seguirmos esta abordagem teórica em problemas da vida real, por iso que recorremos às técnicas de aprendizagem de máquina (técnicas empíricas, data-driven); <br><br>\n",
    "    \n",
    "- E, por fim, o ingrediente fundamental para que seja possível treinar um modelo de ML são os dados. Sem dados, é impossível seguirmos uma abordagem empírica!\n",
    "    \n",
    "Por isso, usamos machine learning apenas no caso em que temos as três condições acima satisfeitas! \n",
    "    \n",
    "No entanto, apenas a terceira é realmente impeditiva (sem dados, não dá pra fazer nada!). \n",
    "    \n",
    "Por outro lado, se existir uma descrição teórica e dados também, nada nos impede de treinar um modelo de ML (só não vai ser a melhor abordagem); \n",
    "    \n",
    "E, se não existir um padrão nos dados, também nada nos impede de treinar um modelo de ML (ele só vai ser horrível). \n",
    "    \n",
    "Por isso que a terceira condição é fundamental, e as duas primeiras, a rigor, menos fundamentais -- embora, pensando em utilidade do que fizemos, de fato precisamos satisfazer as 3 condições. Justo?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\n",
    "\n",
    "Há situações em que a resolução de um problema de negócio demanda o desenvolvimento de um modelo preditivo. Nestes casos, é comum seguirmos uma abordagem data-driven, comumente apoiada por técnicas de aprendizagem de máquina. \n",
    "\n",
    "Neste contexto, podemos dizer que um modelo de machine learning nada mais é do que uma representação matemática do problema sob análise (ou de alguns de seus aspectos), construído teoricamente a partir dos princípios fundamentais que regem este problema.\n",
    "\n",
    "( ) Verdadeiro\n",
    "\n",
    "(x) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    Um modelo <b>empírico</b>, construído segundo uma abordagem <b>data-driven</b>, de fato é uma representação matemática do problema sob análise, mas sua construção se dá a partir de <b>dados</b> coletados, gerados como <b>amostras</b> pelo processo teórico que rege o problema. Se um modelo for construído teoricamente a partir dos princípios fundamentais que regem o problema, dizemos que o modelo é <b>teórico</b>, construído segundo a abordagem <b>theory-driven</b>.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Considere a figura a seguir, sobre o famoso tradeoff *viés/variância* (*bias/variance*):**\n",
    "\n",
    "<img src=https://www.learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png width=400>\n",
    "\n",
    "Sobre este tradeoff, avalie as afirmativas a seguir como verdadeiras ou falsas:\n",
    "\n",
    "- 1 - Dizemos que um modelo tem **alto viés** (bias), se ele sofre de **underfitting**, isto é, se a diferença entre os erros de treino e teste/validação é pequena, e ambos erros são grandes. Este fenômeno tende a ocorrer quando a hipótese não é capaz de capturar corretamente os padrões refletidos na amostra de treino.\n",
    "\n",
    "- 2 - Dizemos que um modelo tem **alta variância** (variance), se ele sofre de **overfitting**, isto é, se a diferença entre os erros de treino e teste/validação é muito grande, sendo os erros de teste/validação muito maiores que os erros de treino. Este fenômeno tende a ocorrer quando a hipótese é tão complexa, que se torna capaz de capturar até mesmo as particularidades (ruídos) da base de treino, perdendo, assim, poder de generalização.\n",
    "\n",
    "Julgando as afirmativas 1 e 2, temos, respectivamente:\n",
    "\n",
    "(x) Verdadeiro / Verdadeiro\n",
    "\n",
    "( ) Falso / Verdadeiro\n",
    "\n",
    "( ) Verdadeiro / Falso\n",
    "\n",
    "( ) Falso / Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Tudo certo!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Considere a figura a seguir, sobre métricas de avaliação de problemas de classificação:**\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png width=200>\n",
    "\n",
    "Neste contexto, julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa:\n",
    "\n",
    "Em um sistema/teste de detecção de doenças extremamente contagiosas, é muito importante que o modelo consiga capturar corretamente todas as pessoas que estão de fato doentes, mesmo que isso implique em indicar erroneamente que algumas pessoas saudáveis estão doentes. \n",
    "\n",
    "Ou seja, em um sistema desses, é importante que os **falsos negativos** sejam minimizados; portanto, o objetivo é **maximizar** a métrica **precision**.\n",
    "\n",
    "( ) Verdadeiro\n",
    "\n",
    "(x) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "De fato, segundo a descrição do problema, estamos interessados em minimizar os falsos negativos. Mas, fazendo isso, a métrica a ser maximizada é o <b>recall</b>, não o precision (vide a imagem acima!)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\n",
    "\n",
    "A validação cruzada é uma técnica muito importante para que tenhamos estatísticas para as métricas de avaliação, sendo também muito utilizada para a determinação de valores adequados para hiperparâmetros de modelos, contribuindo para evitar overfitting.\n",
    "\n",
    "(x) Verdadeiro\n",
    "\n",
    "( ) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Tudo certo!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Julgue as afirmativas a seguir como verdadeiras ou falsas, justificando sua resposta para as afirmativas falsas, se houver alguma**\n",
    "\n",
    " - 1 - O método KNN pode ser usado tanto para classificação quanto para regressão, e consiste em atribuir o target a uma observação de teste como sendo a média dos targets das $k$ observações de treino mais próximas à observação de teste (no caso de classificação, esta \"média\" na verdade é a moda, isto é, um voto de maioria);\n",
    "\n",
    " - 2 - Pensando nos extremos dos valores de $k$: quando $k=1$, o modelo tem alto viés; e quando $k=N$ ($N$ é o número de observações na base de treino), o modelo tem alta variância.\n",
    "\n",
    "Julgando as afirmativas 1 e 2, temos, respectivamente:\n",
    "\n",
    "() Verdadeiro / Verdadeiro\n",
    "\n",
    "( ) Falso / Verdadeiro\n",
    "\n",
    "(x) Verdadeiro / Falso\n",
    "\n",
    "( ) Falso / Falso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Com k=1, levamos em consideração um único vizinho, de modo que o modelo fica extremamente sensível a variações locais -- se por acaso o único vizinho mais próximo for um outlier, nossa decisão será errada, pois considerará apenas este vizinho. De maneira mais ampla, ao considerar uma informação tão local, o estimador foca apenas em informações bem específicas e particulares, potencialmente ruidozas. Portanto, neste caso, há tendência maior de <b>overfitting</b>, isto é, <b> alta variância</b>.\n",
    "\n",
    "Por outro lado, tomando $k=n$, a predição é tomada simplesmente como uma média dos targets da amostra, sem discriminação alguma (no caso de classificação: o target majoritário é sempre predito; no caso de regressão: a média global é sempre predita). Com isso, nós deixamos de capturar o padrão geral, o que caracteriva <b>underfitting</b>, ou seja, neste caso o modelo tem <b>alto viés.</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Julgue a afirmativa a seguir como verdadeira ou falsa, justificando sua resposta se a afirmativa for falsa**\n",
    "\n",
    "Os hiperparâmetros de estimadores, apesar de não serem aprendidos (isto é, determinados diretamente dos dados de treino), influenciam o comportamento do modelo final. Há estimadores com mais, outros com menos hiperparâmetros; alguns mais importantes, outros menos. Mas o fato é que o ajuste de valores adequados para os hiperparâmetros é algo muito importante para a construção de bons modelos!\n",
    "\n",
    "Duas técnicas comumente otimizadas para este fim são o Grid Search e o Random Search.\n",
    "\n",
    "No Grid Search, estabeçecemos alguns valores para cada um dos hiperparâmetros que desejamos otimizar, e então testamos exaustivamente todas as combinações possíveis, uma a uma.\n",
    "\n",
    "(x) Verdadeiro\n",
    "\n",
    "( ) Falso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Certinho!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)Vamos treinar, avaliar e escolher o melhor modelo! Considere o dataset a seguir (use exatamente o mesmo código!):**\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.datasets import make_regression  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples = 400,\n",
    "                          n_features = 5,\n",
    "                       n_informative = 3,\n",
    "                       noise = 20,\n",
    "                       random_state = 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "Com os métodos de aprendizagem KNN (com k=2) e Linear Regression (hiperparâmetros default), assinale a alternativa que contém apenas associações corretas considerando o erro absoluto médio (MAE) com duas casas decimais.\n",
    "\n",
    " - 1 - O melhor modelo é o kNN pois ele obteve um menor erro no conjunto de teste.\n",
    " - 2 - Os erros de teste obtidos foram: 15.89 para a regressão linear; 24.53 para o KNN.\n",
    " - 3 - O melhor modelo é o kNN pois ele obteve um MAE = 0 no treino.\n",
    " - 4 - Os erros de treino obtidos foram: 6.95 para a regressão linear e -0.5 para o KNN.\n",
    " - 5 - O melhor modelo é a regressão linear, em ternos da performance de generalização.\n",
    " - 6 - O modelo knn está overfitado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "RESOLUÇÃO!\n",
    "\n",
    "```\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "lr = LinearRegression()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "avaliacao_teste_knn = np.round(mean_absolute_error(y_test, y_pred_knn), 2)\n",
    "avaliacao_teste_lr = np.round(mean_absolute_error(y_test, y_pred_lr), 2)\n",
    "\n",
    "y_pred_treino_knn = knn.predict(X_train)\n",
    "y_pred_treino_lr = lr.predict(X_train)\n",
    "\n",
    "avaliacao_treino_knn = np.round(mean_absolute_error(y_train, y_pred_treino_knn), 2)\n",
    "avaliacao_treino_lr = np.round(mean_absolute_error(y_train, y_pred_treino_lr), 2)\n",
    "\n",
    "print(\"\\nAvaliação no treino: \")\n",
    "print(f\"\\nMAE TREINO KNN = {avaliacao_treino_knn}\")\n",
    "print(f\"\\nMAE TREINO LR = {avaliacao_treino_lr}\")\n",
    "\n",
    "\n",
    "print(\"\\nAvaliação no teste: \")\n",
    "print(f\"\\nMAE TESTE KNN = {avaliacao_teste_knn}\")\n",
    "print(f\"\\nMAE TESTE LR = {avaliacao_teste_lr}\")\n",
    "\n",
    "```\n",
    "\n",
    "**OUTPUTS**\n",
    "\n",
    "``` \n",
    "Avaliação no treino: \n",
    "\n",
    "MAE TREINO KNN = 13.36\n",
    "\n",
    "MAE TREINO LR = 15.19\n",
    "\n",
    "Avaliação no teste: \n",
    "\n",
    "MAE TESTE KNN = 24.53\n",
    "\n",
    "MAE TESTE LR = 15.89\n",
    "```\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    " - 1) FALSO! KNN foi teve o maior MAE nos dados de teste, portanto o modelo foi pior;\n",
    "    \n",
    " - 2) VERDADEIRO! Sim, basta olhar os outputs no código acima;\n",
    "    \n",
    " - 3) FALSO! Também, basta olhar o output acima que temos MAE = 15.19 nos dados de treino com o KNN;\n",
    "    \n",
    " - 4) FALSO! Os erros nos treino para Regressão Lienar e KNN, respectivamente, são 15.19 e 13.36;\n",
    "    \n",
    " - 5) VERDADEIRO! Basta notar que o modelo de Regressão Linear obteve resultados muito semelhantes tanto nos dados de treino quanto teste. Ele entendeu o que estava acontecendo;\n",
    "    \n",
    " - 6) VERDADEIRO! Observe que nos dados de treino, KNN obteve um MAE pequeno porém, nos dados de teste, seu MAE já foi consideravelmente elevado. Portanto, ele se entendeu bem com os dados de treino, mas não com a generalização do modelo!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## João rascunho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação no treino: \n",
      "\n",
      "MAE TREINO KNN = 13.36\n",
      "\n",
      "MAE TREINO LR = 15.19\n",
      "\n",
      "Avaliação no teste: \n",
      "\n",
      "MAE TESTE KNN = 24.53\n",
      "\n",
      "MAE TESTE LR = 15.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.datasets import make_regression  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples = 400,\n",
    "                          n_features = 5,\n",
    "                       n_informative = 3,\n",
    "                       noise = 20,\n",
    "                       random_state = 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "lr = LinearRegression()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "avaliacao_teste_knn = np.round(mean_absolute_error(y_test, y_pred_knn), 2)\n",
    "avaliacao_teste_lr = np.round(mean_absolute_error(y_test, y_pred_lr), 2)\n",
    "\n",
    "y_pred_treino_knn = knn.predict(X_train)\n",
    "y_pred_treino_lr = lr.predict(X_train)\n",
    "\n",
    "avaliacao_treino_knn = np.round(mean_absolute_error(y_train, y_pred_treino_knn), 2)\n",
    "avaliacao_treino_lr = np.round(mean_absolute_error(y_train, y_pred_treino_lr), 2)\n",
    "\n",
    "print(\"\\nAvaliação no treino: \")\n",
    "print(f\"\\nMAE TREINO KNN = {avaliacao_treino_knn}\")\n",
    "print(f\"\\nMAE TREINO LR = {avaliacao_treino_lr}\")\n",
    "\n",
    "\n",
    "print(\"\\nAvaliação no teste: \")\n",
    "print(f\"\\nMAE TESTE KNN = {avaliacao_teste_knn}\")\n",
    "print(f\"\\nMAE TESTE LR = {avaliacao_teste_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.23162113e+01,  3.02186512e+00,  2.46436718e+01,  1.05402461e+00,\n",
       "        4.07889063e+01, -1.16911302e+01, -8.06616179e+01,  2.85851348e+01,\n",
       "       -3.19424795e-02,  5.22045950e+01, -3.14374284e+01,  6.70927618e+00,\n",
       "        4.29849627e+01, -3.86228032e+01,  3.49935843e+00, -2.73834416e+01,\n",
       "       -8.42144515e+01, -5.86386658e+01,  7.13538404e+00, -1.17543064e+02,\n",
       "       -1.30427327e+01,  3.84615043e-01,  6.38479164e+01,  2.85391484e+01,\n",
       "        4.51242718e+01,  5.89783094e+01, -8.96283176e+01,  5.22104914e+01,\n",
       "       -5.34798541e+01, -3.05930920e+01, -2.98454914e+01, -6.11924481e+01,\n",
       "       -3.40711378e+01,  2.97757364e+01, -9.44659378e+01,  4.38642631e+01,\n",
       "        6.31731057e+01, -1.76393133e+00, -1.85467866e+01, -1.08382816e+02,\n",
       "       -4.51326920e+01,  1.08572806e+01, -1.36404964e+01,  3.58602876e+01,\n",
       "        4.59201494e+01, -2.86857952e+01,  2.66907226e+01,  3.83581153e+01,\n",
       "       -4.26338605e+01,  2.33257115e+01,  5.17683582e+01,  2.47754623e+01,\n",
       "        4.61215040e+00, -5.34798541e+01, -4.70018507e+01, -7.96074990e+01,\n",
       "        6.01140208e+01, -2.13725675e+01,  7.01848683e+01, -8.32310723e+01,\n",
       "        2.28296432e+01,  1.27154144e+01, -3.34152000e+01,  2.13651387e+01,\n",
       "        6.55345880e+01, -3.06025742e+00,  2.89618358e+01, -1.47652446e+01,\n",
       "       -1.83415409e+01, -5.71652184e+01,  9.08964325e+01, -1.53688210e+01,\n",
       "       -2.73834416e+01,  6.70223330e+01,  8.69761382e+01,  5.03582515e+01,\n",
       "        7.21841351e+01, -7.21588406e+01, -3.31212353e+01,  3.69003195e+01,\n",
       "       -3.22825040e+00, -1.38581903e+02,  2.85851348e+01,  1.58008853e+01,\n",
       "        2.28432251e+01,  1.27154144e+01,  2.36940373e+01,  8.62112241e+01,\n",
       "        3.25579705e+01, -1.14718260e+02,  9.61430340e+01,  3.94086458e+01,\n",
       "        2.23159612e+01, -6.08322400e+01,  1.09116666e+01,  1.44965283e+01,\n",
       "       -5.05130939e+01, -3.10044789e+01, -3.36736313e+00, -2.57180914e+00,\n",
       "       -7.16705466e+01, -8.32310723e+01,  1.95097666e+01,  8.20529492e+00,\n",
       "       -9.72131221e+00, -1.39624379e+01,  3.50788675e+01, -8.13633544e+00,\n",
       "       -1.03219582e+02,  6.93076564e+00,  5.63459947e+01,  3.81852209e+01,\n",
       "       -6.71558596e+00,  8.71582360e+01, -1.76072546e+01,  1.23725698e+00,\n",
       "       -5.46609578e+01, -4.04127650e+01,  3.49935843e+00, -4.70018507e+01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
