{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Redes Neurais Artificiais**\n",
    "\n",
    "## **1. Introdução**\n",
    "\n",
    "Seres humanos são muito bons em aprender! Isto se deve a nosso sistema nervoso, que pode ser entendido como uma grande rede de neurônios interligados.\n",
    "\n",
    "Um dos objetivos da Inteligência Artificial é o de construir sistemas inteligentes, com capacidade cognitiva similar à dos humanos.\n",
    "\n",
    "Assim sendo, faz sentido construirmos um modelo inspirado no sistema nervoso, não é mesmo?\n",
    "\n",
    "Assim nasceram as __Redes Neurais Artificiais (RNAs)__! Essas redes foram inspirados no neurônio biológico e na rede composta por eles. \n",
    "\n",
    "#### **1.1 Breve introdução histórica**\n",
    "\n",
    "A história das redes neurais começa com a primeira modelagem matemática de um neurônio, elaborada por Warren McCulloch e Walter Pitts em 1943. A inspiração é justificada: desde seus primórdios a IA flerta com a ideia de construir máquinas capazes de resolver problemas gerais como humanos - nada mais natural, portanto, do que tentar emular as estruturas básicas do cérebro humano.\n",
    "\n",
    "A anatomia de um neurônio que inspirou o modelo de McCulloch-Pitts é apresentada abaixo. A informações corre por ela da esquerda para a direita aqui:\n",
    "\n",
    "- Os dendritos recebem os outputs de outros neurônios que se tornam inputs deste;\n",
    "- Os sinais dos dentritos vão para o corpo celular do neurônio, onde íons, positivos e negativos, são combinados. Toda vez que a diferença de potencial atinge certo limiar, um pulso elétrico é enviado ao axônio;\n",
    "-  Por fim, o axônio transmite o sinal vindo do corpo celular (nosso output) para outros neurônios, reinciando o processo.\n",
    "\n",
    "Há cerca de 10 bilhões deles no cérebro, fortemente conectados uns aos outros: há estimativas de 60 trilhões de conexões (\"sinapses\") entre eles [1](https://www.amazon.com.br/Redes-Neurais-Princ%C3%ADpios-Simon-Haykin/dp/8573077182). O processo descrito acima acontece o tempo todo e é totalmente paralelizado. Quanto mais relevante for um input, mais ele será reforçado nas sinapses que ocorrem nos dendritos.\n",
    "\n",
    "Em uma rede neural, tem-se um processo semelhante por meio de uma estrutura computacional também conhecida como neurônio. Neste neurônio, os estímulos são as entradas de um dado problema (i.e. atributos/variáveis de um dataset), essas entradas são processadas por meio de uma soma ponderada, são avaliados por um threshold e o resultado gera uma saída, que pode também ser enviada para outros neurônios.\n",
    "\n",
    "<img src=\"https://www.ee.co.za/wp-content/uploads/2019/07/Application-of-machine-learning-algorithms-in-boiler-plant-root-cause-analysis-Fig-1.jpg\" width=\"400\" />\n",
    "\n",
    "Os inputs fazem o papel da informação que chega no neurônio real pelos dendritos, os pesos e a soma fazem o papel das reações químicas, a função de ativação aplica o threshold e o output tem paralelo com o axônio.\n",
    "\n",
    "A ideia geral dessa estrutura é que, por meio de uma soma ponderada, esse modelo de aprendizado de máquina consiga realizar uma formulação matemática que caracterize a saída em termo da entrada, semelhante à modelos de regressão linear.\n",
    "\n",
    "Essa estrutura é conhecida como **perceptron**. Entretanto, o perceptron é capaz de desenvolver soluções simples. Para resolução de problemas mais complexos, comumente tem-se uma conexão de diversos neurônios, de forma que cada neurônio (ou conjunto deles) possa focar em uma determinada parte da solução, de forma a dividir uma tarefa complexa em tarefas mais simples.\n",
    "\n",
    "Embora hoje o Perceptron seja amplamente reconhecido como um algoritmo, ele foi inicialmente concebido como uma máquina de reconhecimento de imagem. Recebe esse nome por desempenhar a função humana de percepção, vendo e reconhecendo imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Matemática do Perceptron\n",
    "\n",
    "Nesse nosso perceptron temos 6 __inputs__: $x_1, x_2, x_3, x_4, x_5$ e $x_6$ (retângulos em laranja à esquerda), que correspondem a nossas features de entrada e um __output__ binário que pode ser 0 ou 1.\n",
    "\n",
    "Como os valores de input são convertidos em output?\n",
    "\n",
    "1. cada uma das features é multiplicada por um peso distinto que denominamos de $w_1$\n",
    "\n",
    "2. somamos os valores de todos os neurônios e adicionamos um bias que é um termo que independe dos dados de input\n",
    "\n",
    "$$ \\sum_j{w_j x_j}  + bias = x_1 w_1 + x_2 w_2 + x_3 w_3 + x_4 w_4 + x_5 w_5 + x_6 w_6 + bias $$\n",
    "\n",
    "3. definimos um threshold tal que o output recebe zero se essa soma for menor que o threshold ou 1 caso contrário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "output = \n",
    "\\left\\{ \n",
    "  \\begin{aligned}\n",
    "    0, & \\ \\ if \\sum_j{w_j x_j} + bias \\leq threshold\\\\\n",
    "    1, & \\ \\ if \\sum_j{w_j x_j} + bias > threshold\\\\\n",
    "\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "Variando esses pesos e threshold conseguimos diferentes modelos preditivos.\n",
    "Podemos perceber que esse perceptron mais simples é muito parecido com uma regressão linear!\n",
    "\n",
    "$$ y = a x_1 + b x_2 + c x_3 + d $$  \n",
    "\n",
    "Os coeficientes angulares são chamados de pesos ($w$) nas redes neurais enquanto o intercepto é chamado de bias (viés). Assim como na regressão linear o algorítimo aprendia os valores dos coeficientes angulares e do intercepto, __nas redes neurais o algorítmo irá aprender os valores dos pesos e do bias__.\n",
    "\n",
    "O termo b na equação é frequentemente chamado de viés, porque controla a predisposição do neurônio para disparar um 1 ou 0, independentemente dos pesos.\n",
    "\n",
    "Esses perceptrons são chamados de single-layer Perceptrons e não são muito utilizados por não conseguirmos resolver problemas complexos com eles. Assim como na regressão linear, **eles só conseguem resolver problemas que são linearmente separáveis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Mão no código: Perceptron\n",
    "Vamos utilizar uma base conhecida para testarmos o Perceptron usando o querido sklearn. Mais para frente veremos como criar esse mesmo modelo utilizando uma biblioteca de Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.886\n",
      "Accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Importa o dataset do iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Separa em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Vamos fazer um scale dos nossos dados\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Instancia o Perceptron\n",
    "pp = Perceptron(random_state=42)\n",
    "\n",
    "# Fita o Perceptron\n",
    "pp.fit(X_train, y_train)\n",
    "\n",
    "# Faz as predições nos dados de treino e teste\n",
    "y_pred = pp.predict(X_test)\n",
    "y_pred_train_ppn = pp.predict(X_train)\n",
    "\n",
    "# Printa acurácia no treino e teste\n",
    "print('Accuracy train: %.3f' % accuracy_score(y_train, y_pred_train_ppn))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 MLP\n",
    "\n",
    "Imagine que, para um neurônio biológico, podemos realizar algumas atividades mais simples, como por exemplo retirar a mão de um lugar extremamente quente (como uma panela). Pode-se ter uma quantidade pequena de neurônios que, dado o estímulo gerado, possa desenvolver a solução simples de retirar a mão do lugar quente e evitar queimaduras. Por outro lado, se tivermos uma atividade mais complexa como um quebra-cabeça ou uma equação matemática para resolver, a solução pode não vir imediatamente, sendo necessário que o nosso cérebro utilize diversos neurônios para resolução desse quebra cabeça.\n",
    "\n",
    "Da mesma forma funciona um neurônio no contexto de aprendizagem de máquina, dada uma tarefa mais complexa, pode-se precisar de mais neurônios para desenvolver a solução corretamente. Quando utilizamos vários neurônios, formamos uma rede de neurônios, também conhecida como rede neural, podendo existir diferentes tipos de redes, como por exemplo as redes neurais multicamadas (MLP), redes convolucionais (CNNs) e redes recorrentes.\n",
    "\n",
    "\n",
    "Agora, podemos combinar uma sequência de perceptrons e criar um __Multilayer Perceptron (MLP)__\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz1.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Mão no código: MLP\n",
    "\n",
    "[sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.971\n",
      "Accuracy test: 0.889\n"
     ]
    }
   ],
   "source": [
    "# importa modelo\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Instancia o MLP\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Fita o MLP\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Faz as predições nos dados de treino e teste\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "y_pred_train_mlp = mlp.predict(X_train)\n",
    "\n",
    "# Printa acurácia no treino e teste\n",
    "print('Accuracy train: %.3f' % accuracy_score(y_train, y_pred_train_mlp))\n",
    "print('Accuracy test: %.3f' % accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhoramos bastante nosso Perceptron adicionando mais neurônios à ele!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entender um pouco melhor como funcionam as RNAs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Qual a estrutura de uma Rede Neural Artificial (RNA)?**\n",
    "\n",
    "Como visto, uma rede neural é composta por varios neurônios que são estruturados para, em conjunto, gerar uma saída. Para uma rede neural básica, também conhecida como uma rede neural multicamada, tem-se como elementos básicos:\n",
    "\n",
    "- **Unidades (ou neurônios)**: são as unidades mínimas de processamento da rede neural, onde as operações matemáticas são realizadas;\n",
    "\n",
    "- **Camadas**: há três tipos de camadas:\n",
    "\n",
    "\t- **Camada de entrada (input layer)**: é a camada de entrada de dados. O número de unidades nesta camada é igual ao número de features (variáveis independentes) do modelo;\n",
    "\n",
    "\t- **Camadas ocultas (hidden layers)**: são as camadas de processamento. O número de camadas ocultas, bem como o número de neurônios em cada uma delas, é variável, dependendo do problema e dos dados. Em geral, a melhor estratégia é experimentar diferentes números de camadas e de neurônios;\n",
    "\n",
    "\t- **Camada de saída (output layer)**: é a camada que dá a resposta da rede neural, isto é, o valor predito por ela. O número de unidades nesta camada depende do tipo de output desejado, e é o que determina o target (variável dependente) do modelo.\n",
    "\t\n",
    "#### E porque utilizamos camadas escondidas?\n",
    "\n",
    "Imagine que dado os atributos de um problema, cada neurônio receberá essas entradas e calculará os pesos. Esse resultado é processado e enviado para uma segunda camada, podendo esta camada também associar pesos para cada novo neurônio. Dessa forma, tem-se um __aprendizado sequencial em que cada camada pode aprimorar o que foi aprendido nas camadas anteriores tomando decisões mais complexas e mais abstratas__. Sendo assim, em uma rede neural podemos não apenas aprender diferentes partes de um problema por meio do uso de vários neurônios, como podemos também aprimorar essa informação por meio de camadas. \n",
    "\n",
    "<img src=\"https://gadictos.com/wp-content/uploads/2019/05/bp1.png\" width=\"400\" />\n",
    "\n",
    "As camadas e neurônios são interligadas entre si através de conexões. A cada conexão, associa-se um **peso** (que denotamos pela letra **W**). O objetivo da RNA é **\"aprender\" os pesos que melhor se ajustam aos dados!**\n",
    "\n",
    "#### Quantas camadas ocultas e quantos neurônios preciso colocar em cada uma?\n",
    "\n",
    "Para saber essa resposta só com um search de hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de ativação\n",
    "\n",
    "A função de ativação é análoga à [taxa de disparo do potencial](https://en.wikipedia.org/wiki/Action_potential) de ação no cérebro.\n",
    "\n",
    "As funções de ativação (activation functions) são equações matemáticas que processam os dados de entrada, $z=b+\\sum_i w_i x_i$, e determinam qual será a saída de um determinado neurônio. Elas basicamente __decidem se desativam ou ativam os neurônios__ para obter a saída desejada, daí o nome, funções de ativação. Neurônios desativados são aqueles cujo valor é menor ou igual que zero.\n",
    "\n",
    "Qual foi a função de ativação utilizada no perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função degrau (Step function)\n",
    "\n",
    "<img src=https://iq.opengenus.org/content/images/2021/11/step-func-2.png width=200 text=\"https://iq.opengenus.org/binary-step-function/\">\n",
    "\n",
    "Essa é a função de ativação mais simples que temos e veremos outras logo a frente.\n",
    "\n",
    "Vantagens:\n",
    "- introduzir não linearidade\n",
    "- restringem os valores de saídas para um determinado intervalo, evitando que nossa saída atinja tamanhos muito grandes\n",
    "\n",
    "Problemas no uso da função degrau:\n",
    "- só funciona para classificação\n",
    "- não é útil quando há várias classes\n",
    "- gradiente (derivada) dela é zero, o que dificulta o processo de backpropagation. Ou seja, se você calcular a derivada de f(x) em relação a x, ela será 0.\n",
    "\n",
    "$$f'(x) = 0, \\ para \\ todo \\ x$$\n",
    "\n",
    "\n",
    "Na próxima aula veremos outros tipos de função de ativação.\n",
    "\n",
    "\n",
    "Até agora o que aprendemos:\n",
    "\n",
    "<img src=https://iq.opengenus.org/content/images/2021/11/step-func-1-2.png width=500 text=\"https://iq.opengenus.org/binary-step-function/\" >\n",
    "\n",
    "Rede neural é uma grande sequência de composição de funções!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Mas e o tal do \"Deep Learning\"?**\n",
    "\n",
    "Conforme descrito inicialmente, o conceito de redes neurais foi evoluindo ao longo do tempo. Sendo assim, enquanto na década de 1950 tinhamos o perceptron para estruturar problemas lineares, na década de 1960 surgiram as funções de ativação para resolução de problemas também não lineares. \n",
    "\n",
    "Semelhantemente, em 1980 foram propostas as redes neurais multicamadas (MLP), que são redes neurais com a estrutura ilustrada no tópico 2, estruturadas para desenvolver problemas não lineares e de maior complexidade, sendo a ideia geral dessa rede termos 1) vários neurônios em uma camada, cada um (ou conjunto deles) responsável por partes do aprendizado, e 2) uma arquitetura em camadas em que os neurônios da próxima camada recebem o resultado do processamento dos neurônios da camada anterior, sendo o objetivo dessa arquitetura aprimorar features a cada camada até alcançar um nivel de complexidade de features que possa resolver o problema.\n",
    "\n",
    "De forma geral, quanto mais camadas essa rede tenha, maior tendência a resolver problemas mais complexos. **Quando precisamos de muitas camadas ocultas e muitos neurônios, chamamos essa rede de rede profunda, originando o termo Deep Learning**. \n",
    "\n",
    "Isso originou um novo ramo de pesquisa em redes neurais, principalmente com o aumento de acesso a informação e bases de dados, bem como o maior suporte a placas de vídeo e recursos computacionais em geral. Com isso, por volta de 2012, passaram a surgir outras formas de conectar um neurônio em camadas profundas, de forma que hoje o termo Deep Learning é conhecido não apenas por uma rede neural profunda, como também o uso dessas abordagens, tendo como destaque redes convolucionais e redes recorrentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. E quando eu uso Redes Neurais?**\n",
    "\n",
    "No atual cenário de Big Data em que vivemos (há muitos dados em todo o lugar!), os modelos de Redes Neurais e Deep Learning são cada vez mais utilizados!\n",
    "\n",
    "Isto é possível porque a performance destes modelos aumenta conforme mais dados (e diversidade desses dados) são utilizados, diferentemente dos modelos tradicionais, cuja performance é estabilizada depois de certa quantidade de dados!\n",
    "\n",
    "\n",
    "<img src=https://lh6.googleusercontent.com/L4wC5XJ-nsLV3pXqNvKTPB8bXx4-NYeFBXuToFiaM-7scsmJrQ8We8RHEZGa_yy2XHVmhRKOSZwKjhzLPKyLXdxcKuGQkUh1tndvimGYfBofExdrzW60QTfyZUmpYwRTCOPsBLQN text=\"https://machine-learning.paperspace.com/wiki/data-science-vs-machine-learning-vs-deep-learning\" width=400>\n",
    "\n",
    "\n",
    "Então, é de se esperar que os modelos de Deep Learning funcionem melhor nos cenários em que há **muitos dados disponíveis**.\n",
    "\n",
    "No entanto, se houver tempo e recursos computacionais disponíveis, é sempre uma ideia construir também um modelo de Deep Learning juntamente de outros modelos de Machine Learning, e então comparar qual tem melhor performance! :)\n",
    "\n",
    "O problema é que quanto mais camadas adicionamos na nossa rede, maior o tempo de treinamento necessário:\n",
    "\n",
    "<img src=http://neuralnetworksanddeeplearning.com/images/training_speed_4_layers.png text=\"http://neuralnetworksanddeeplearning.com/chap5.html\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alguns tipos de redes neurais\n",
    "\n",
    "<img src=\"https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZoo20042019.png\" width=\"600\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Referências**\n",
    "\n",
    "https://playground.tensorflow.org/\n",
    "\n",
    "https://www.deeplearningbook.com.br\n",
    "\n",
    "https://keras.io\n",
    "\n",
    "https://www.tensorflow.org/tutorials\n",
    "\n",
    "https://www.louisbouchard.ai/densenet-explained/\n",
    "\n",
    "https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\n",
    "\n",
    "https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141\n",
    "\n",
    "[Álgebra Linear](https://mlfromscratch.com/tag/linear-algebra/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercício**\n",
    "\n",
    "Suponha que seus pais têm uma aconchegante cama e café da manhã no campo com um livro de visitas no saguão cadastrado no Airbnb. Todos os hóspedes podem escrever uma nota antes de partir e, até agora, muito poucos saem sem escrever uma nota curta ou uma citação inspiradora. Alguns até deixam desenhos de Molly, o cachorro da família.\n",
    "\n",
    "No antigo depósito, você se deparou com uma caixa cheia de livros de visitas que seus pais mantiveram ao longo dos anos. Seu primeiro instinto? Vamos ler tudo!\n",
    "\n",
    "Depois de ler algumas páginas, você acabou de ter uma ideia muito melhor. Por que não tentar entender se os hóspedes deixaram uma mensagem positiva ou negativa?\n",
    "\n",
    "Você é um Cientista de Dados, e logo se atentou que esta é a tarefa perfeita para um classificador binário!\n",
    "\n",
    "Então você escolheu uma página de um livro de visitas aleatoriamente para usar como conjunto de treinamento, transcreveu todas as mensagens e deu uma classificação de sentimento positivo ou negativo.\n",
    "\n",
    "As mensagens estão descritas como uma lista na variável \"corpus\" abaixo, enquanto a classificação dada por você está na variável \"target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'We enjoyed our stay so much. The weather was not great, but everything else was perfect.',\n",
    "    'Going to think twice before staying here again. The wifi was spatty and the rooms smaller than advertised.',\n",
    "    'The perfect place to relax and recharge.',\n",
    "    'Never had such a relaxing vacation.',\n",
    "    'The pictures were misleading, so I was expecting the common areas to be bigger. But the service was good.',\n",
    "    'There were no clean lines when I got ti my room and the breakfast options were not that many.',\n",
    "    'Was expecting it to be a bit far from historical downtown, but it was almost impossible to drive through those narrow roads.',\n",
    "    'I thought that waking up with the chickens was fun, but i was wrong.',\n",
    "    'Great place for a quick getaway from the city. Everyone is friendly and polite',\n",
    "    \"Unfortunately it was raining during our stay, and there weren\\'t many options for indoors activity. Everything was great, but there is litteraly no other aprionts besides being in the rain.\",\n",
    "    'The town festival was postponed, so the area was a complete ghost town. We were the only guests. Not the experience I was looking for.',\n",
    "    'We had a lovely time. It\\'s a fantastic place to go with the children, they loved all the animals.',\n",
    "    'A little bit off the beaten track, but completely worth it. You can hear the birds sing in the morning and then you are greeted with the biggest, sincerest smiles from the owners.Loved it!',\n",
    "    'It was good to be outside in the country, visiting old town. Everything was prepared to the uprest detail.',\n",
    "    'Staff was friendly. Going to come back for sure.',\n",
    "    'They didn\\'t have enought staff for the amount of guests. It took some time to get our breakfast and we had to wait 20 minutes to get more information about old town.',\n",
    "    'The pictures looked way different.',\n",
    "    'Best weekend in the countryside I\\'ve ever had.',\n",
    "    'Terrible. Slow staff, slow town. Only good thing was being surrounded by nature.',\n",
    "    'Not as clean as advertised. Found some cobwebs in the corner of the room.',\n",
    "    'It was a peaceful getaway in the countryside.',\n",
    "    'Everyone was nice. Had a good time.',\n",
    "    'The kids loved running around in nature, we loved the old town. Definitely going back.',\n",
    "    'Had worse experience.',\n",
    "    'Surprised this was much different than what was on the website.',\n",
    "    'Not that windblowing.'\n",
    "]\n",
    "\n",
    "# 0: negative sentiment 1: positive\n",
    "targets = [1,0,1,1,0,0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,1,1,1,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabendo disso, respondas as seguintes questões:\n",
    "\n",
    "1) Qual a sequência de passos que você deve fazer para solucionar esse problema? Escreva essa sequência para guiar sua solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta:\n",
    "- separar treino e teste\n",
    "- converter meus dados para valores numéricos utilizando o tfidf com stopwords e lowercase\n",
    "- fitar meu modelo nos dados de treino\n",
    "- fazer a predição nos dados de teste\n",
    "- avaliar meu modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Agora vamos colocar essa solução em prática! Como modelos de ML queremos que você compare o __Perceptron__ e o __MLP__ estudados nessa aula. Para começar, considere ambos com os parâmetros default da biblioteca do sklearn e utilize como métrica a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia treino:  1.0\n",
      "Acurácia test:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Resposta:\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# - separar treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, targets, test_size=0.2, random_state=123)\n",
    "\n",
    "# - converter meus dados para valores numéricos utilizando o tfidf com stopwords e lowercase\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# - fitar meu modelo nos dados de treino\n",
    "pc = Perceptron(random_state=42)\n",
    "pc.fit(X_train, y_train)\n",
    "\n",
    "# - fazer a predição nos dados de teste\n",
    "y_pred = pc.predict(X_test)\n",
    "y_pred_train = pc.predict(X_train)\n",
    "\n",
    "# - avaliar meu modelo\n",
    "print(\"Acurácia treino: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Acurácia test: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x109 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 130 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.25179518],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.09317376515158406\n"
     ]
    }
   ],
   "source": [
    "print(X_train.todense().max())\n",
    "print(X_train.todense().min())\n",
    "print(X_train.todense().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia treino:  1.0\n",
      "Acurácia test:  1.0\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# - fazer a predição nos dados de teste\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "y_pred_train_mlp = mlp.predict(X_train)\n",
    "\n",
    "# - avaliar meu modelo\n",
    "print(\"Acurácia treino: \", accuracy_score(y_train, y_pred_train_mlp))\n",
    "print(\"Acurácia test: \", accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Agora, crie um loop no qual você varie o parâmetro hidden_layer_sizes do MLPClassifier entre 2 e 10 e compare os valores da acurácia para cada um deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de treino:  {2: 0.7, 3: 0.6, 4: 0.7, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0}\n",
      "Scores de test:  {2: 0.6666666666666666, 3: 0.5, 4: 0.5, 5: 0.8333333333333334, 6: 0.5, 7: 0.8333333333333334, 8: 0.8333333333333334, 9: 0.8333333333333334, 10: 0.8333333333333334}\n"
     ]
    }
   ],
   "source": [
    "# Resposta\n",
    "scores_train = {}\n",
    "scores_test = {}\n",
    "for i in range(2,11):\n",
    "    mlp = MLPClassifier(random_state=42, hidden_layer_sizes=i)\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # - fazer a predição nos dados de teste\n",
    "    y_pred_mlp = mlp.predict(X_test)\n",
    "    y_pred_train_mlp = mlp.predict(X_train)\n",
    "\n",
    "    scores_train[i] = accuracy_score(y_train, y_pred_train_mlp)\n",
    "    scores_test[i] = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(\"Scores de treino: \", scores_train)\n",
    "print(\"Scores de test: \", scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb5f626699f206ef97176a4f092b8d9f6e52ae1f84b4bb3163daf9eb25ca3519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
