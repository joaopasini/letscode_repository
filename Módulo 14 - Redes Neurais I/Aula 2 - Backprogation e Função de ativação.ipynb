{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Redes Neurais Artificiais**\n",
    "\n",
    "## **Reprise**\n",
    "\n",
    "<img src=https://iq.opengenus.org/content/images/2021/11/step-func-1-2.png width=500 text=\"https://iq.opengenus.org/binary-step-function/\" >\n",
    "\n",
    "#### E como a RNA aprende os pesos? Quero entender um pouco melhor estes modelos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow graphviz pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Forward Propagation x Backward Propagation**\n",
    "\n",
    "As redes neurais tem como objetivo realizar o aprendizado de pesos que melhor se ajustam aos dados de entrada e essa \"aprendizagem\" é realizada através de duas fases:\n",
    "\n",
    "- **Forward Propagation**;\n",
    "- **Backward Propagation**.\n",
    "\n",
    "No __forward propagation__, a informação propaga na direção habitual (da camada de input para a de output) na rede neural: features são lidas na camada de input, passam pelo processamento nas camadas ocultas, e a resposta (target) é predita na camada de output. \n",
    "\n",
    "Para que a predição seja realizada, os neurônios nas camadas ocultas e de output realizam as seguintes duas etapas de cálculo:\n",
    "\n",
    "- 1. Uma combinação linear entre o output da camada anterior (que denotamos pela letra **a**) e os pesos da camada atual (denominados de **W**). Assim, se tivermos n ligações a combinação linear que teremos será:\n",
    "\n",
    "<center>\n",
    "<img src=https://latex.codecogs.com/gif.latex?z%5E%7Batual%7D%20%3D%20W_0%5E%7Batual%7D%20&plus;%20%5Cleft%20%28%20W_1%5E%7Batual%7D%5Ctimes%20a_1%5E%7Banterior%7D%20%5Cright%29%20&plus;%20%5Cleft%28%20W_2%5E%7Batual%7D%20%5Ctimes%20a_2%5E%7Banterior%7D%20%5Cright%20%29%20&plus;%20%5Ccdots%20&plus;%20%5Cleft%20%28%20W_n%5E%7Batual%7D%20%5Ctimes%20a_n%5E%7Banterior%7D%20%5Cright%29) width=700>\n",
    "</center>\n",
    "\n",
    "- 2. Aplica-se uma **função de ativação** $f(x)$ não-linear à combinação linear acima. \n",
    "\n",
    "As principais funções de ativação utilizadas são:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*4ZEDRpFuCIpUjNgjDdT2Lg.png\n",
    "\" width=\"600\" />\n",
    "</center>\n",
    "\n",
    "O cálculo realizado por um único neurônio é bem parecido com um **perceptron**, ilustrado a seguir:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://img2.gratispng.com/20180619/oav/kisspng-multilayer-perceptron-machine-learning-statistical-5b2996bdb9dcd2.4724873615294522217613.jpg\" width=\"400\" />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notação do feedforward\n",
    "\n",
    "$$z^{atual} = W_n^{atual} \\ast x_n^{anterior}   + b^{atual} = \\sum_n{W_n^{atual} x_n^{anterior}}   + b^{atual}$$\n",
    "$$a^{atual} = f(z^{atual})$$\n",
    "\n",
    "Na camada de output teremos que:\n",
    "\n",
    "$$\\hat{y} = a^{atual}$$\n",
    "\n",
    "E podemos calcular nossa função de custo (vamos aqui considerar o MSE, por exemplo):\n",
    "\n",
    "$$C = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/profile/Sandra-Vieira-7/publication/312205163/figure/fig1/AS:453658144972800@1485171938968/a-The-building-block-of-deep-neural-networks-artificial-neuron-or-node-Each-input-x.png\" width=\"400\" text=\"https://www.researchgate.net/publication/312205163_Using_deep_learning_to_investigate_the_neuroimaging_correlates_of_psychiatric_and_neurological_disorders_Methods_and_applications\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"forward_pass.png\" width=300>\n",
    "</center>\n",
    "\n",
    "[Link](https://ml4a.github.io/demos/simple_forward_pass/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual função de ativação devo utilizar?\n",
    "\n",
    "A escolha das funções de ativação também pode ser variável, mas costuma-se utilizar:\n",
    "\n",
    "- **Sigmoid** (para problemas de classificação binários) ou **Softmax** (para problemas de classificação multiclasse) na camada de output\n",
    "- **ReLu** (Rectified Linear Unit) nas camadas ocultas\n",
    "\n",
    "\n",
    "Essas __funções de ativação__, quando utilizadas nas camadas ocultas, permitem que __adicionemos não linearidade__ na resolução da nossa solução. Se observamos a figura do perceptron ilustrada acima, teremos sempre uma equação linear para representação do nosso problema, já que teremos basicamente uma soma ponderada. Entretanto, muitas vezes nossa base de dados requer uma equação não linear para representar o problema. A tendência é que, quanto mais difícil o problema seja, mais chances da resolução ser não linear.\n",
    "\n",
    "Sendo assim, um processo comum é, após a soma ponderada, gerar uma saída não linear por meio das funções de ativação.\n",
    "\n",
    "Quando a __função de ativação é utilizada em camadas de saída, o objetivo é estruturar aquela saída de acordo com a saída do nosso problema__. Nesse contexto, a função softmax estrutura a saída de forma a poder realizar uma classificação multiclasse, da mesma forma que a função sigmoid estrutura a saída de um problema binário.\n",
    "\n",
    "Já a __ReLU tem o papel de jogar para zero qualquer valor negativo, gerando uma matriz muito mais esparsa__. Com isso teremos uma matriz com vários zeros e alguns não zeros o que __força a rede a focar nestes últimos tornando muito mais eficiente o tempo computacional de treino__. Isso também contruibui com a __diminuição do \"vanishing gradient problem\"__, que discutiremos nas próximas aulas, o que permite que o modelo aprenda mais rápido e performe melhor.\n",
    "\n",
    "Ao fim do forward propagation, na camada de output, calculamos a **função de perda**, que quantifica qual a **diferença entre as predições feitas pela rede neural e os valores reais do target dos dados**. Cada tipo de problema tem uma função de perda própria.\n",
    "\n",
    "Queremos que as predições sejam sempre o mais próximas o possível dos valores reais!\n",
    "\n",
    "Isto é feito ao propagarmos a informação na direção contrária (de trás pra frente) na rede neural, o que caracteriza o chamado __backward propagation__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Backward propagation__\n",
    "<img src=https://cdn-images-1.medium.com/max/540/1*7CJRMAomDwc8HBtaD6LqlQ.gif text=\"https://www.louisbouchard.ai/densenet-explained/\" width=500>\n",
    "\n",
    "Nesse processo de __backward propagation__ os pesos $W_i$ são atualizados de acordo com sua contribuição no erro final e esse atualização acontece de trás para frente na rede. Uma vez que o erro propagado chega na primeira camada outra amostra é iniciada alimentando a rede neural. \n",
    "\n",
    "Este processo de forward e backward propagation é feito iterativamente, várias vezes utilizando todo o dataset. Cada vez que o dataset inteiro passa por esse processo chamamos de **epoch**.\n",
    "\n",
    "O objetivo do backward propagation é **determinar os pesos que miminizem a função de perda!** A cada epoch, os pesos são **atualizados**, de modo que a função de perda é sempre reduzida em direção ao seu mínimo.\n",
    "\n",
    "<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como esses pesos são atualizados?\n",
    "\n",
    "A forma como esses pesos são atualizados para reduzir a função de perda depende do **otimizador** escolhido. Os otimizadores são objetos que representam o procedimento matemático de minimização da função de perda.\n",
    "\n",
    "Os principais otimizadores utilizados são: \n",
    "\n",
    "- __Gradiente Descendente (GD)__,\n",
    "- **Stochastic Gradient Descent (SGD)**,\n",
    "- **Adam** \n",
    "- **RMSProp** \n",
    "\n",
    "(vale a pena testar cada um deles!)\n",
    "\n",
    "### Gradient Descent\n",
    "Você começa definindo os valores do parâmetro inicial e, a partir daí, o gradiente descendente usa o cálculo para ajustar iterativamente os valores para que eles minimizem a função de custo fornecida em cada uma das epochs.\n",
    "\n",
    "<img src=https://static.wixstatic.com/media/3eee0b_4aff9459e3ad43ae9b9e18b2c5631fc1~mv2.jpg/v1/fill/w_360,h_178,al_c,lg_1,q_90/3eee0b_4aff9459e3ad43ae9b9e18b2c5631fc1~mv2.webp width=30 text=\"https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\">\n",
    "\n",
    "Nessa equação $\\theta$ representa nossos pesos $W$ e $J(\\theta)$ é nossa função custo (MSE, por exemplo). Lembrando que a função custo é uma fórmula matemática que permite que nosso modelo de ML analise o quão bem ele fitou nos dados.\n",
    "\n",
    "Assim, podemos concluir dessa equação que a atualização dos parâmetro $\\theta$ depende do seu valor anterior, qual a taxa de variação a função de custo $J(\\theta)$ devido ao $\\theta$ e do learning rate $\\alpha$. Nessa estratégia o objetivo é chegarmos no valor mínimo dá nossa função de custo avaliando o gradiente (derivada) da nossa função:\n",
    "\n",
    "<img src=https://static.wixstatic.com/media/3eee0b_ed42ef8479934026980c15c679df0821~mv2.png/v1/fill/w_360,h_224,al_c,q_90,usm_0.66_1.00_0.01/3eee0b_ed42ef8479934026980c15c679df0821~mv2.webp width=400 text=\"https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\">\n",
    "\n",
    "O learning rate $\\alpha$ é o valor responsável por definir qual o tamanho do passo de cada iteração. Se considerarmos um valor muito grande para o learning rate, podemos nunca chegar no valor de mínimo enquanto se utilizarmos um valor muito baixo podemos demorar muito para chegar.\n",
    "\n",
    "<img src=https://static.wixstatic.com/media/3eee0b_08ae4ed9e6504acbb3bd37320c20f77e~mv2.png/v1/fill/w_360,h_187,al_c,q_90,usm_0.66_1.00_0.01/3eee0b_08ae4ed9e6504acbb3bd37320c20f77e~mv2.webp width=400 text=\"https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\">\n",
    "\n",
    "Para saber como está performando nosso learning rate podemos plotar seu valor versus quanto o erro está variando.\n",
    "\n",
    "<img src=https://806230.smushcdn.com/1739487/wp-content/uploads/2020/10/plot-min.png text=\"https://sdsclub.com/stochastic-gradient-descent-vs-gradient-descent-a-head-to-head-comparison/\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hora do gif\n",
    "\n",
    "##### Gradiente descentente unidimensional\n",
    "\n",
    "A curva representada por $C(w)$ corresponde a função de custo que queremos minimizar.\n",
    "\n",
    "<img src=https://mlfromscratch.com/content/images/2019/12/gradient-descent-optimized.gif width=600 text=\"https://mlfromscratch.com/neural-networks-explained/\">\n",
    "\n",
    "Se o gradiente das derivadas parciais for positivo damos um passo à esquerda, e damos um passo à direita quando negativo.\n",
    "\n",
    "##### Gradiente descentente bidimensional\n",
    "\n",
    "A superfície representada corresponde a função de custo que queremos minimizar.\n",
    "\n",
    "<img src=https://miro.medium.com/max/598/1*hUd744hDEEGx0-ypWGhrkw.gif width=300 text='https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c'>\n",
    "\n",
    "__Vantagens:__\n",
    "\n",
    "- Computação fácil.\n",
    "- Fácil de implementar.\n",
    "- Fácil de entender.\n",
    "\n",
    "__Desvantagens:__\n",
    "\n",
    "- Pode prender em mínimos locais.\n",
    "- Os pesos são alterados após o cálculo do gradiente em todo o conjunto de dados. Portanto, se o conjunto de dados for muito grande, isso pode levar anos para convergir para os mínimos.\n",
    "- Requer grande memória para calcular o gradiente em todo o conjunto de dados.\n",
    "\n",
    "Para quem quiser saber mais sobre o gradiente descendente e sobre derivadas eu recomendo o capítulo \"2.4 The engine of neural networks: Gradient-based\n",
    "optimization\" do livro \"Deep Learning with Python, 2nd Edition\" do Françõis Chollet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "No SGD a derivada é computada considerando apenas um ponto por vez, o que evita o problema de memória.\n",
    "\n",
    "<img src=https://static.wixstatic.com/media/3eee0b_2f20c4c9902844718350e189e57fd909~mv2.png/v1/fill/w_740,h_290,al_c,q_90,usm_0.66_1.00_0.01/3eee0b_2f20c4c9902844718350e189e57fd909~mv2.webp width=500 text=\"https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\">\n",
    "\n",
    "No SGD em cada passo o gradiente descendente é cálculado para cada amostra enquanto no GD ele é cálculado para todo o dataset. Isso significa que os pesos são atualizados no GD apenas após todo o dataset ter passado pela rede e termos os valores de $\\hat{y}$ para cada amostra. No SGD, os pesos são atualizados toda vez que uma amostra chega ao final da rede neural.\n",
    "\n",
    "Então após 1 epoch o GD teria calculado apenas um gradiente descendente enquando o SGD teria calculado `X_train.shape[0]` vezes.\n",
    "\n",
    "__Vantagem:__\n",
    "\n",
    "- O requisito de memória é menor em comparação com o algoritmo GD, pois a derivada é calculada tomando apenas 1 ponto de cada vez.\n",
    "- Minimiza a função de custo de forma mais rápida que o GD (por ter mais atualizações dos pesos em 1 epoch)\n",
    "\n",
    "__Desvantagens:__\n",
    "\n",
    "- O tempo necessário para completar 1 época é grande comparado ao algoritmo GD.\n",
    "- Ainda leva muito tempo para convergir.\n",
    "- Também pode ficar preso em mínimos locais.\n",
    "- SGD oscilar mais e necessita de muito mais passos\n",
    "\n",
    "\n",
    "### Mini-bath gradient descent (MGD)\n",
    "Para conseguir o melhor dos dois podemos utilizar o Mini-bath gradient descent (MGD) que considera uma pequena amostra de dataset de treino em cada iteração. Esse otimizador é mais estável que o SGD.\n",
    "\n",
    "O MGD divide o conjunto de dados em vários lotes e após cada lote os parâmetros são atualizados.\n",
    "\n",
    "<img src=https://static.wixstatic.com/media/3eee0b_afe86f0d655d4b218f002ce82c1c25ac~mv2.png/v1/fill/w_740,h_190,al_c,q_90,usm_0.66_1.00_0.01/3eee0b_afe86f0d655d4b218f002ce82c1c25ac~mv2.webp width=500 text=\"https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\">\n",
    "\n",
    "__Vantagens:__\n",
    "\n",
    "- Menor complexidade de tempo para convergir em comparação com o algoritmo SGD padrão.\n",
    "\n",
    "__Desvantagens:__\n",
    "\n",
    "- A atualização do MB-SGD é muito ruidosa em comparação com a atualização do algoritmo GD.\n",
    "-  Leva mais tempo para convergir do que o algoritmo GD.\n",
    "-  Pode ficar preso em mínimos locais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GD x SGD x MGD\n",
    "\n",
    "__Gradient Descent__ -> Batch Size = Size of Training Set\n",
    "\n",
    "__Stochastic Gradient Descent__ -> Batch Size = 1\n",
    " \n",
    "__Mini-Batch Gradient Descent__ -> 1 < Batch Size < Size of Training Set\n",
    "\n",
    "E se o conjunto de dados não for dividido uniformemente pelo tamanho do lote?\n",
    "\n",
    "Isso acontece com frequência ao treinar um modelo. Significa simplesmente que o lote final tem menos amostras do que os outros lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!\n",
    "Melhorar texto com https://ml4a.github.io/ml4a/how_neural_networks_are_trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop\n",
    "Como vimos nos outros otimizadores, a escolha do learning rate é fundamental tanto para a convergência quanto para o tempo de convergência. Para minimizar esse problema, o RMSProp utiliza um decaimento exponencial do learning rate. Dessa forma, o learning rate é alto no início da aprendizagem e seu valor cai ao longo do tempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Moment Estimation (Adam)\n",
    "Adam pode ser considerado uma combinação de Stochastic Gradient Descent e RMSProp com momento.\n",
    "\n",
    "#### Momento?\n",
    "\n",
    "O conceito de momento aqui é o mesmo que utilizamos em física. Suponha uma bola rolando em uma superfície sem atrito. O momento faz com que ela continue seu movimento sem parar.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=https://miro.medium.com/max/400/1*i1Qc2E0TVlPHEKG7LepXgA.gif width=500>\n",
    "</center>\n",
    "\n",
    "<figcaption align = \"center\"><b>Fig.1 - Descida do momento com decay_rate = 1.0 (sem decaimento).</b></figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem momento:\n",
    "\n",
    "$$ \\theta = \\theta - learning\\_rate * gradient$$\n",
    "\n",
    "Com momento:\n",
    "\n",
    "$$\\theta = \\theta - learning\\_rate * gradient + previous\\_theta * decay\\_rate$$\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=https://miro.medium.com/max/875/1*pgpFmmIXJBvlReVwlRQ-Yg.png width=700>\n",
    "</center>\n",
    "\n",
    "<figcaption align = \"center\"><b>Fig.2 - Como o momento atua passo-a-passo.</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "Normalmente, a taxa de decaimento (decay_rate) é escolhida em torno de 0,8 a 0,9 – é como uma superfície com um pouco de atrito, então, eventualmente, a bolinha desacelera e para.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=https://miro.medium.com/max/500/1*zVi4ayX9u0MQQwa90CnxVg.gif width=400>\n",
    "</center>\n",
    "\n",
    "<figcaption align = \"center\"><b>Fig.3 - Momentum (magenta) vs. Gradient Descent (ciano) em uma superfície com um mínimo global (o poço esquerdo) e um mínimo local (o poço direito).</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "Qual a diferença entre GD com e sem momentum:\n",
    "\n",
    "- Momentum se move mais rápido por causa de todo o momentum que acumula\n",
    "- O momento tem uma chance de escapar de mínimos locais (porque o momento pode impulsioná-lo para fora de um mínimo local).\n",
    "- Percorrer melhor as regiões de planalto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Gradient (AdaGrad)\n",
    "\n",
    "Mantém o controle da soma do gradiente ao quadrado e usa isso para adaptar o gradiente em diferentes direções.\n",
    "\n",
    "O gradiente médio para features esparsas geralmente é pequeno, então essas features são treinadas em uma taxa muito mais lenta.\n",
    "\n",
    "O AdaGrad aborda esse problema usando esta ideia: quanto mais você já atualizou uma feature, menos você a atualizará no futuro, dando assim uma chance para as demais (por exemplo, as features esparsas) se atualizarem. Em termos visuais, o quanto você atualizou essa feature é para dizer o quanto você se moveu nessa dimensão, e essa noção é capturada pela soma cumulativa do gradiente ao quadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Como construir um modelo de Rede Neural Artificial em Python?**\n",
    "\n",
    "Vamos iniciar reescrevendo nosso perceptron com a biblioteca `keras`. Para isso precisamos introduzir alguns conceitos novos e aproveitaremos para revisar outros:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Importa o dataset do iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    " \n",
    "# Separa em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Vamos fazer um scale dos nossos dados\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário de termos + Keras\n",
    "\n",
    "[Sequencial](https://keras.io/api/models/sequential/)\n",
    "\n",
    "O bloco de construção inicial do Keras é um modelo, e o modelo mais simples é chamado de _sequencial_. Um modelo Keras sequencial é um pipeline linear (uma pilha) de camadas de redes neurais. Outras formas de criar modelos são com o [Functional API](https://keras.io/guides/functional_api) e [Model Subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing)\n",
    "\n",
    "[Input layer](https://keras.io/api/layers/core_layers/input/)\n",
    "\n",
    "É a camada de input que contem nossas features. O dado de entrada deve ser um array de uma única coluna.\n",
    "\n",
    "[Dense layer](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "Dense layers (camadas densas), são camadas neurais densamente conectadas. Isso significa que todos os neurônios de uma camada se conectam com todos os neurônios da camada seguinte. Essas camadas também são chamadas de fully connected).\n",
    "\n",
    "<img src=https://www.i2tutorials.com/wp-content/media/2019/09/Deep-learning-41-i2tutorials.png width=500>\n",
    "\n",
    "Dense implements the operation: output = activation(dot(input, kernel)+ bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and # bias is a bias vector created by the layer (only applicable if use_bias is True)\n",
    "\n",
    "[Funções de Custo](https://keras.io/api/losses/)\n",
    "\n",
    "O objetivo das funções de perda é calcular a quantidade que um modelo deve procurar minimizar durante o treinamento.\n",
    "- CategoricalCrossentropy: many-class classification\n",
    "- SparseCategoricalCrossentropy: many-class classification\n",
    "- BinaryCrossentropy: two-class classification\n",
    "- MeanSquaredError\n",
    "- Accuracy\n",
    "- AUC\n",
    "- KLDivergence\n",
    "- CosineSimilarity\n",
    "\n",
    "[Métricas](https://keras.io/api/metrics/)\n",
    "\n",
    "Uma métrica é uma função usada para avaliar o desempenho do seu modelo.\n",
    "\n",
    "As funções de métrica são semelhantes às funções de perda, exceto que os resultados da avaliação de uma métrica não são usados ​​ao treinar o modelo. Observe que você pode usar qualquer função de perda como métrica.\n",
    "\n",
    "- CategoricalCrossentropy: target é uma matrix com cada coluna representando uma classe\n",
    "- SparseCategoricalCrossentropy: target é uma única coluna com as classes sendo representadas de 0 até n.\n",
    "- BinaryCrossentropy: target binário\n",
    "- MeanSquaredError\n",
    "- KLDivergence\n",
    "- CosineSimilarity\n",
    "\n",
    "[Funções de ativação](https://keras.io/api/layers/activations)\n",
    "\n",
    "Função aplicada nas camadas ocultas e de output visando aumentar a complexidade do nosso modelo.\n",
    "\n",
    "<center>\n",
    "<img src=https://miro.medium.com/max/875/1*B24qtkjFBD43ClulZtLmVA.png width=600 text=\"https://medium.com/analytics-vidhya/activation-functions-and-loss-functions-for-neural-networks-how-to-pick-the-right-one-542e1dd523e0\">\n",
    "</center>\n",
    "\n",
    "[Inicializador de pesos](https://keras.io/api/layers/initializers)\n",
    "\n",
    "Como queremos iniciar os pesos $W$.\n",
    "\n",
    "[Otimizador](https://keras.io/api/optimizers/)\n",
    "\n",
    "O mecanismo pelo qual o modelo se atualizará com base nos dados de treinamento que ele vê, para melhorar seu desempenho.\n",
    "SGD (with or without momentum)\n",
    "- RMSprop\n",
    "- Adam\n",
    "- Adagrad\n",
    "\n",
    "[Epochs]()\n",
    "\n",
    "Quantas vezes o loop de treinamento deve iterar sobre todos os dados.\n",
    "\n",
    "Uma época significa que cada amostra no conjunto de dados de treinamento teve a oportunidade de atualizar os parâmetros internos do modelo. Uma época é composta por um ou mais lotes e geralmente assume valores bem grandes como 100, 500, 1000 e até mais. Ao final de cada epoch temos uma estimativa do erro do nosso modelo.\n",
    "\n",
    "[Batch]()\n",
    "\n",
    "O tamanho do lote a ser usado em cada época de descida do Mini-batch GD.\n",
    "O número de exemplos de treinamento considerados para calcular os gradientes para um etapa de atualização de peso.\n",
    "Normalmente entre 8 e 128 que são processados ​​simultaneamente pelo modelo. O número de amostras é\n",
    "geralmente uma potência de 2, para facilitar a alocação de memória na GPU.\n",
    "\n",
    "We will now train the model for 20 epochs (20 iterations over all samples in the train-\n",
    "ing data) in mini-batches of 512 samples.\n",
    "\n",
    "[Kernel Inicializer]()\n",
    "\n",
    "Cada neurônio pode ser inicializado com pesos específicos. Keras oferece algumas opções, as mais comuns estão listadas a seguir:\n",
    "\n",
    "- __random_uniform:__ os pesos são inicializados para valores pequenos uniformemente aleatórios em (-0,05, 0,05). Em outras palavras, qualquer valor dentro do intervalo dado tem a mesma probabilidade de ser desenhado.\n",
    "- __random_normal:__ Os pesos são inicializados de acordo com uma Gaussiana, com média zero e desvio padrão pequeno de 0,05. Para aqueles que não estão familiarizados com uma gaussiana, pense em uma forma de curva de sino simétrica.\n",
    "- __zero:__ Todos os pesos são inicializados com o valor zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# declarar forma modelo\n",
    "\n",
    "\n",
    "# adicionar os layers\n",
    "# para remover o último layer usamos o .pop()\n",
    "\n",
    "\n",
    "# compilar o modelo\n",
    "\n",
    "\n",
    "# Fit do modelo\n",
    "\n",
    "\n",
    "# Test the model after training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 neurônios de input * 3 neurônios de output + 3 bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP no Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP\n",
    "\n",
    "\n",
    "# declarar forma modelo (Sequencial? Funcional?)\n",
    "\n",
    "\n",
    "# adicionar os layers\n",
    "\n",
    "\n",
    "# compilar o modelo: Configuring the learning process\n",
    "\n",
    "\n",
    "# Fit do modelo\n",
    "\n",
    "\n",
    "# Test the model after training using evaluate\n",
    "\n",
    "\n",
    "print(f'\\nTrain results - Loss: {train_results[0]:.2f} - Accuracy: {100*train_results[1]:.1f}%')\n",
    "print(f'\\nTest results - Loss: {test_results[0]:.2f} - Accuracy: {100*test_results[1]:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira camada\n",
    "# 2 neurônios de input * 100 neurônios ocultos + 100 bias\n",
    "\n",
    "# Camada output\n",
    "# 100 neurônios ocultos * 3 neurônios de output + 3 bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saber quantidade de parâmetros: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegar estrutura da rede neural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saber pesos\n",
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferência: Usando um modelo após o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot da função de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que o modelo converge e tanto a performance de treino e de teste ficam equivalentes. Essa performance e convergência sugerem que escolhemos uma boa função de custo para nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo:\n",
    "\n",
    "Neste exemplo, usaremos o **MNIST**, o famoso dataset de dígitos (números de 0 a 9) escritos à mão. O objetivo do nosso modelo será o de classificar digítos, com base em imagens. Assim sendo, temos um **problema de classificação multiclasse** (pois os dados serão classificados em uma dentre 10 classes possíveis, de 0 a 9).\n",
    "\n",
    "Primeiramente, lemos nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa libs\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dos dados de treino e teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limita tamanho dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que acima já temos separados os dados de treino e de teste!\n",
    "\n",
    "Pra garantir maior rapidez do algoritmo, **reescalamos** as **features** para que tenham valores entre 0 e 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para reescalar as features, as dividimos pelo valor máximo das features de treino\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos converter nossos targets em matrizes com a mesma quantidade de linhas que anteriormente, mas agora com uma coluna para cada classe utilizando o to_categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos separar nossos dados de treino em um conjunto para treino e outro para validação. No Keras podemos tanto selecionar uma porcentagem dos dados de treino para validação, quanto passar um conjunto de validação pré-determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, definimos a arquitetura de nossa rede neural, usando o Keras!\n",
    "\n",
    "Vamos construir uma rede neural simples, com 3 camadas ocultas densas e 25 neurônios em cada camada, com a função de ativação **ReLu**. Para a camada de output, usamos a **Softmax**, dado que temos um problema de classificação multiclasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de funções úteis do Keras\n",
    "\n",
    "\n",
    "# definição da arquitetura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, compilamos a rede neural, explicitando o otimizador e a função de perda desejadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o otimizador RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dois parâmetros na função acima são importantes:\n",
    "- **\"loss\"**, que é a função de perda a ser minimizada. Esta função depende do tipo de problema que queremos resolver. Como temos um problema de classificação multiclasse, a função de perda adequada é ou a \"categorical_crossentropy\" ou a \"sparse_categorical_crossentropy\".\n",
    "- **\"optimizer\"**, que é o otimizador que utilizaremos para minimizar a função de perda. A escolha do otimizador é bem mais livre: é uma boa ideia testar diferentes otimizadores! Os mais utilizados são: **Adam**, **SGD** e **RMSprop**.\n",
    "\n",
    "Por fim, treinamos a rede neural! Basta usar o método \".fit()\", determinando o número de epochs bem como os dados de treino e validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, pronto! A rede neural está treinada!\n",
    "\n",
    "Como em todo problema de classificação, podemos utilizar o classification report para avaliar sua performance nos dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo as predições\n",
    "\n",
    "\n",
    "# Extrai classe com maior probabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe o classification report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso a performance não seja suficiente, entram os próximos passos, muito comuns em todo projeto de Deep Learning:\n",
    "\n",
    "- Tentar arquiteturas diferentes de Redes Neurais;\n",
    "- Tunar os hiperparâmetros;\n",
    "- Mudar o otimizador;\n",
    "- Investigar a ocorrência de overfitting, e usar técnicas de regularização;\n",
    "\n",
    "...entre outras!\n",
    "\n",
    "Lembre-se: a construção de um modelo de Deep Learning é um processo altamente **iterativo**, de tentativa e erro!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que a performance de treino não mudou, mas pioramos nossa generalização no teste\n",
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Referências**\n",
    "\n",
    "https://playground.tensorflow.org/\n",
    "\n",
    "https://www.deeplearningbook.com.br\n",
    "\n",
    "https://keras.io\n",
    "\n",
    "https://www.tensorflow.org/tutorials\n",
    "\n",
    "https://www.louisbouchard.ai/densenet-explained/\n",
    "\n",
    "https://www.kdnuggets.com/2020/12/optimization-algorithms-neural-networks.html\n",
    "\n",
    "https://valueml.com/multi-layer-perceptron-by-keras-with-example/\n",
    "\n",
    "https://ml4a.github.io/ml4a/how_neural_networks_are_trained/\n",
    "\n",
    "[Três formas de montar redes neurais com o Keras](https://developpaper.com/three-methods-of-constructing-neural-network-with-keras/)\n",
    "\n",
    "[Álgebra Linear](https://mlfromscratch.com/tag/linear-algebra/)\n",
    "\n",
    "[Comparação entre otimizadores](https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c)\n",
    "\n",
    "[Binary Cross Entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)\n",
    "\n",
    "[Derivada no backpropagation: exemplo demostrando Regra da Cadeia](https://www.jeremyjordan.me/neural-networks-training/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercício**\n",
    "\n",
    "Você trabalhará com o conjunto de dados da Reuters, um conjunto de notícias curtas e seus tópicos, publicados pela Reuters em 1986. É um conjunto de dados de teste simples e amplamente utilizado para classificação de texto. Nele encontramos 46 temas diferentes com alguns tópicos aparecendo mais do que outros, mas cada tópico tem pelo menos 10 exemplos no conjunto de treinamento.\n",
    "\n",
    "Esse dataset foi originalmente gerado pela análise e pré-processamento do conjunto de dados clássico Reuters-21578. Cada noticia é codificada como uma lista de índices de palavras (inteiros). Por conveniência, as palavras são indexadas pela frequência geral no conjunto de dados, de modo que, por exemplo, o inteiro \"3\" codifica a 3ª palavra mais frequente nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importe os dados do `tensorflow.keras.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # num_words=10000 restringe os dados as 10.000 palavras mais frequentes encontradas nos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual o shape dos datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecione o primeiro elemento de train_data e retorne seu tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecione o terceiro elemento de train_data e retorne seu tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que cada linha do dataset de treino tem um tamanho diferente, que pré-processamento podemos fazer para deixar todas com o mesmo tamanho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: adicionar zeros até chegar em um valor de coluna limite, limitar a quantidade para a menor, ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugestão de pré-processamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    \"\"\"Multi-hot encode your lists to turn them into vectors of 0s and 1s. This would\n",
    "    mean, for instance, turning the sequence [8, 5] into a 10,000-dimensional vec-\n",
    "    tor that would be all 0s except for indices 8 and 5, which would be 1s. Then you\n",
    "    could use a Dense layer, capable of handling floating-point vector data, as the\n",
    "    first layer in your model\"\"\"\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o método `to_categorical` do `tensorflow.keras.utils` ou o `LabelBinarizer` do `sklearn.preprocessing` para converter os labels de uma coluna para n colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a montar nossa rede neural!\n",
    "\n",
    "- Quantas camadas ocultas colocar?\n",
    "- Quantos neurônios em cada camada oculta?\n",
    "- Qual será a função de cada camada oculta?\n",
    "- Quantos neurônios na camada de saída?\n",
    "- Qual a função na cada camada de saída?\n",
    "- Meu problema é de classificação ou regressão? Se for de classificação, é binário ou multi-classe?\n",
    "- Qual função custo utilizar?\n",
    "- Qual métrica para avaliar meu modelo?\n",
    "- Qual otimizador usar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plote as curvas da função custo e sua métrica por epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seu modelo está overfitando, underfitando ou está bom? Porquê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seu modelo não ficou bom, o que você pode fazer para melhorá-lo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a acurácia entre as seguintes redes neurais:\n",
    "\n",
    "1. Uma camada densa com 64 neurônios > uma camada densa com 64 neurônios > uma camada densa com 46 neurônios\n",
    "2. Uma camada densa com 64 neurônios > uma camada densa com 4 neurônios > uma camada densa com 46 neurônios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: The model now peaks at ~71% validation accuracy, an 8% absolute drop. This drop is\n",
    "mostly due to the fact that we’re trying to compress a lot of information (enough\n",
    "information to recover the separation hyperplanes of 46 classes) into an intermediate\n",
    "space that is too low-dimensional. The model is able to cram most of the necessary\n",
    "information into these four-dimensional representations, but not all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça outros testes diminuindo e aumentando tanto a quantidade de neurônios quanto a de camadas ocultas.\n",
    "\n",
    "### Fim!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprofundamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: Binary Cross-Entropy Loss / Log Loss\n",
    "\n",
    "This is the most common loss function used in classification problems. The cross-entropy loss decreases as the predicted probability converges to the actual label. It measures the performance of a classification model whose predicted output is a probability value between 0 and 1.\n",
    "\n",
    "<img src=https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/1_common-loss-functions_1.png width=400 text=\"https://builtin.com/machine-learning/common-loss-functions\">\n",
    "\n",
    "When the number of classes is 2, it’s binary classification.\n",
    "common-loss-functions\n",
    "\n",
    "<img src=https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/2_common-loss-functions.png width=200 text=\"https://builtin.com/machine-learning/common-loss-functions\" >\n",
    "\n",
    "When the number of classes is more than 2, it’s multi-class classification.\n",
    "common-loss-functions\n",
    "\n",
    "<img src=https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/3_common-loss-functions.png width=500 text=\"https://builtin.com/machine-learning/common-loss-functions\">\n",
    "\n",
    "We derive the cross-entropy loss formula from the regular likelihood function, but with logarithms added in.\n",
    "\n",
    "Extraído de https://builtin.com/machine-learning/common-loss-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notação matricial das equações\n",
    "\n",
    "Denotamos cada ativação por $a_{neuron}^{(layer)}$, por exemplo $a^{(1)}_2$ corresponderia ao neurônio número três na segunda camada (contamos a partir de 0). Assim, o número abaixo (subscrito) corresponde a qual neurônio estamos falando, e o número acima (sobrescrito) corresponde a qual camada estamos olhando, ambos contando a partir de zero.\n",
    "\n",
    "Denotamos cada peso por $w_{to, from}^{(layer)}$, onde $to$ é denotado como $j$ e $from$ denotado como $k$, assim,  $w^2_{2,3}$ significa indo para o terceiro neurônio na terceira camada, a partir do neurônio quatro na camada anterior (segunda camada), pois contamos a partir do zero.\n",
    "\n",
    "Exemplo de vetor de ativação para a camada zero:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "    a_0^{0}\\\\\n",
    "    a_1^{0}\\\\\n",
    "    \\vdots \\\\\n",
    "    a_n^{0}\\\\\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "Exemplo de matriz de pesos que conectam cada neuron a próxima camada:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    w_{0,0} & w_{0,1} & \\cdots & w_{0,k}\\\\\n",
    "    w_{1,0} & w_{1,1} & \\cdots & w_{1,k}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w_{j,0} & w_{j,1} & \\cdots & w_{j,k}\\\\\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Combinando esses dois com a matriz de bias e encapsulando na função sigmóide:\n",
    "\n",
    "$$\n",
    "\\sigma \\left(\n",
    "    \\begin{bmatrix}\n",
    "    w_{0,0} & w_{0,1} & \\cdots & w_{0,k}\\\\\n",
    "    w_{1,0} & w_{1,1} & \\cdots & w_{1,k}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w_{j,0} & w_{j,1} & \\cdots & w_{j,k}\\\\\n",
    "    \\end{bmatrix}\n",
    "    \\, \n",
    "    \\begin{bmatrix}\n",
    "    a_0^{0}\\\\\n",
    "    a_1^{0}\\\\\n",
    "    \\vdots \\\\\n",
    "    a_n^{0}\\\\\n",
    "    \\end{bmatrix}\n",
    "    +\n",
    "    \\begin{bmatrix}\n",
    "    b_0\\\\\n",
    "    b_1\\\\\n",
    "    \\vdots \\\\\n",
    "    b_n\\\\\n",
    "    \\end{bmatrix}\n",
    "    \\right)\n",
    "    $$\n",
    "\n",
    "Podemos escrever de outra forma:\n",
    "\n",
    "$$ a^{(1)}=\n",
    "\\sigma\\left(\n",
    "\\boldsymbol{W}\\boldsymbol{a}^{0}+\\boldsymbol{b}\n",
    "\\right) $$\n",
    "\n",
    "Ou reduzir a notação ainda mais e escrever:\n",
    "\n",
    "$$ a^{(1)}=\n",
    "\\sigma\\left(\n",
    "\\boldsymbol{z}\n",
    "\\right)$$\n",
    "\n",
    "Com isso conseguimos a matriz de todas as ativações da segunda camada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aula_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb5f626699f206ef97176a4f092b8d9f6e52ae1f84b4bb3163daf9eb25ca3519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
