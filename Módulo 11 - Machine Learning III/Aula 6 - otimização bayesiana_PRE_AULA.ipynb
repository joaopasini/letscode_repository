{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca63e0fd-88f5-457b-91eb-d0e35eabf640",
   "metadata": {},
   "source": [
    "# Aula 6 - otimização bayesiana\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Otimização bayesiana\n",
    "- 3) Introdução a LIME e SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7d506-cea3-4c94-a5e8-d237eb8abd8c",
   "metadata": {},
   "source": [
    "Atenção! Precisaremos de uma instalação: \n",
    "\n",
    "[hyperopt](http://hyperopt.github.io/hyperopt/)\n",
    "\n",
    "Então faça o: `pip install hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a8dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a78a9-5b0f-4724-8890-b048714d064f",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "Desde que conhecemos os primeiros estimadores utilizados para a construção de modelos, uma preocupação adicional nos acompanhou: o ajuste de valores dos hiperparâmetros.\n",
    "\n",
    "Quase todos os estimadores que conhecemos têm um ou mais **hiperparâmetros** associados.\n",
    "\n",
    "Como vimos, os hiperparâmetros influenciam o comportamento do modelo (e, portanto, são muito importantes), mas eles não são determinados a partir dos dados! É nosso dever, como cientistas de dados, fornecer valores adequados para os hiperparâmetros.\n",
    "\n",
    "No começo de nossa jornada, nós utilizávamos os valores default para os hiperparâmetros, ou então, mudávamos manualmente alguns valores, para sensibilizar a influência dos hiperparâmetros no modelo final.\n",
    "\n",
    "Mas logo percebemos que essa não era a melhor abordagem --- precisávamos de um método mais sistemàtico para a busca de bons valores para os hiperparâmetros!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946469f-1da8-4761-9bf2-5bcaf25890ca",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "Para este fim, introduzimos inicialmente o **grid search**, que **testa exaustivamente** combinações explícitas de valores de hiperparâmetros.\n",
    "\n",
    "Apesar de simples e direta, esta é uma abordagem computacionalmente muito custosa (sentimos isso na pele, ao rodar rotinas de grid search que demoram horas, ou até mesmo dias!). \n",
    "\n",
    "De fato, esta é uma abordagem de força bruta que, aliás, não nos dá garantia nenhuma: é perfeitamente possível que nenhuma das combinações que estabelecemos seja boa boa! Oras, há muitos casos em que o **espaço de hiperparâmetros** é infinito (basta considerar um hiperparâmetro dado por um float que não é limitado)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b382c0-b197-46ca-ae69-26ac3c2df40e",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "Para endereçar este problema, introduzimos então o **random search**.\n",
    "\n",
    "Neste caso, ao invés de disponibilizarmos valores específicos de hiperparâmetros a serem combinados, disponibilizamos **intervalos** ou explicitamente **distribuições de probabilidade** sobre o espaço de parâmetros de cada hiperparâmetro, e **amostramos valores aleatórios** destas distribuições para gerar as combinações.\n",
    "\n",
    "Com essa abordagem estocástica, há a possibilidade de encontrarmos boas combinações, que não estariam inclusas nos valores explícitos que passamos para o grid search.\n",
    "\n",
    "Por outro lado, com o random search também não temos garantia alguma que as melhores combinações serão encontradas, sobretudo porque **todas as combinações são amostradas de maneira aleatória**. Ou seja, todas as combinações são amostradas **sem considerar** a performance das combinações anteriores. Com esta metodologia, fica difícil garantirmos que efetivamente encontraremos boas combinações..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb3a0a-8cbe-491b-a089-32b59501041c",
   "metadata": {},
   "source": [
    "Metodologia de grid search (à esquerda) vs random search (à direita):\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Minrui-Zheng/publication/328252103/figure/fig4/AS:766093471801344@1559662325592/Distribution-of-sampled-hyperparameters-a-grid-search-b-random-search.png width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb798839-fb1f-433a-a26f-c508ccdd4481",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "Então, podemos nos perguntar: qual seria o próximo passo? Existiria um método ainda mais eficiente e \"educado\" para fazer a otimização de hiperparâmetros?\n",
    "\n",
    "A resposta é: sim! Hoje, conheceremos o método de **otimização Bayesiana**, aplicada à otimização de hiperparâmetros!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbcd9d2-502e-4940-b930-e0be8b5b3a9d",
   "metadata": {},
   "source": [
    "_________\n",
    "_________\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a18788-1c54-4cf1-a404-36284736b7af",
   "metadata": {},
   "source": [
    "## 2) Otimização Bayesiana\n",
    "\n",
    "O objetivo da otimização baeysiana é o mesmo que tínhamos com o grid e random search: **determinar os valores adequados para um conjunto de hiperparâmetros**, de modo que a combinação de valores **proporcione os melhores valores para uma métrica de avaliação calculada em dados de validação**.\n",
    "\n",
    "O que muda com a otimização baeysiana é a forma como isso será feito.\n",
    "\n",
    "Já descrevemos os problemas que ambos grid e random search têm. Sobretudo, o fato das combinações de valores dos hiperparâmetros serem independentes entre si, sem levar em consideração combinações anteriores, que poderiam ser boas.\n",
    "\n",
    ">Pra entender isso melhor, imagine o cenário em que queremos otimizar 3 hiperparâmetros.\n",
    "<br><br>\n",
    ">Pode ser que, em uma combinação, encontremos bons valores para 2 dos 3 hiperparâmetros; ja, na próxima, como os 3 valores serão novos, pode ser que os 3 sejam ruins. Não seria interessante de conseguíssemos manter a informação sobre os valores bons que encontramos?\n",
    "\n",
    "Esse é o espírito da otimização baeysiana!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4e8a9-4478-4dee-9672-5bca3fec89f1",
   "metadata": {},
   "source": [
    "Pra entender isso intuitivamente, considere a figura a seguir (suponha que o \"score\" é um erro, então, quanto menor, melhor):\n",
    "\n",
    "<img src=https://miro.medium.com/max/1120/1*MiNXGrkk5BbjfkNAXZQSNA.png width=400>\n",
    "\n",
    "Pergunta: onde você concentraria a busca por valores do hiperparâmetro `n_estimators`?\n",
    "\n",
    "Olhando pro gráfico, existe claramente uma região no espaço do hiperparâmetro `n_estimators` que é melhor: menos de 200 árvores.\n",
    "\n",
    "**Uma vez que temos este conhecimento**, realmente não faz sentido algum que os próximos valores que vamos testar sejam maiores que 200, não é mesmo?\n",
    "\n",
    "Esse é o espírito da otimização bayesiana: **utilizamos a informação que temos quanto ao score alcançado com valores iniciais de hiperparâmetros para guiar a escolha dos próximos valores!**\n",
    "\n",
    "E aqui já fica claro o porquê do método receber o título \"bayesiano\": de fato, estamos nos utilizando da \"filosofia\" bayesiana de ajuste de estratégia conforme agregamos novas informações! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3d82d-4da6-4b56-a4fe-7db1bc557f5a",
   "metadata": {},
   "source": [
    ">E é por isso que a otimização bayesiana é tão mais eficiente que as estratégias anteriores: gastamos um pouco mais de energia para propor combinações de hiperparâmetros **levando em consideração** as combinações passadas e suas respectivas perfomances.\n",
    "<br><br>\n",
    "Com isso, podemos focar apenas em testar **combinações promissoras**, e não precisamos gastar energia em procurar por combinações que sabemos não ser tão boas.\n",
    "\n",
    "Faz sentido, não é mesmo?\n",
    "\n",
    "Agora, precisamos apenas entender **como** é possível implementar isso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8aebca-203b-4f1a-8088-43b8688b77df",
   "metadata": {},
   "source": [
    "### 2.1) Função objetivo\n",
    "\n",
    "É razoável assumirmos que existe uma função que relaciona a métrica de performance (score) que temos interesse de otimizar e os hiperparâmetros, não é mesmo?\n",
    "\n",
    "Sabendo que as métricas de performance essencialmente comparam os targets preditos com os targets reais, e sabendo que os targets preditos (pela hipótese) são influenciados pelos hiperparâmetros, é bem natural que assumamos que esta função existe.\n",
    "\n",
    "Agora, o ponto é que pode ser extremamente difícil escrever esta função explicitamente. Como nosso objetivo será encontrar valores que **otimizam** a função, costumamos chamá-la de **função objetivo**. \n",
    "\n",
    "Mas, veja, queremos otimizar uma função objetivo **sem nem saber qual é sua dependência funcional com os hiperparâmetros**. Problemas deste tipo são chamados de **otimização de caixa-preta**, e existem várias técnicas para abordá-los. Recomendo [este material](https://www.lix.polytechnique.fr/~dambrosio/blackbox_material/Cassioli_1.pdf) aos interessados.\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Abraham-Duarte/publication/236164556/figure/fig1/AS:393408515461120@1470807307227/Schematic-representation-of-the-black-box-optimization-framework.png width=500>\n",
    "\n",
    "Quando formos pra prática, construiremos a função objetivo implicitamente, como o resultado retornado por uma **métrica de avaliação** dado o treinamento de um modelo. \n",
    "\n",
    "Na prática, isso nos será suficiente, pois bastará que tomemos **alguns pontos** desta função, para seguir com sua otimização, isso graças à introdução do surrogate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b6a23-dfc4-4fc5-ba1e-6318b1aafa51",
   "metadata": {},
   "source": [
    "### 2.2) Surrogate model\n",
    "\n",
    "Na prática, iremos apenas **avaliar alguns pontos da função objetivo** e construir um **modelo probabilístico dela** com base nestes pontos, que serão tratados como **amostras**.\n",
    "\n",
    "Este modelo probabílistico é conhecido como **surrogate model (modelo substituto ou emulador)**, pois ele emula probabilisticamente o que seria a função real, sem a necessidade dela ser reconstruída explicitamente. E o melhor, dado que o modelo surrogate é bem mais simples que a função objetivo, será muito mais fácil otimizá-lo do que a função objetivo em si!\n",
    "\n",
    "<img src=https://www.researchgate.net/profile/Seung-Seop-Jin-2/publication/297605027/figure/fig1/AS:339392045568000@1457928777016/Concept-of-sequential-surrogate-modelling.png width=600>\n",
    "\n",
    "O ponto é que nosso modelo surrogate será atualizado **de maneira bayesiana**, isto é, levando em consideração scores anteriores, para sugerir as próximas combinações de hiperparâmetros de maneira mais principada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b440f-f5e0-4385-9b25-98dcdea9b623",
   "metadata": {},
   "source": [
    "Operacionalmente, seguiremos o seguinte passo-a-passo:\n",
    "\n",
    "- Construiremos um modelo probabilístico surrogate para a função objetivo;\n",
    "- Otimizaremos o modelo surrogate, encontrando bons valores para os hiperparâmetros nesta função;\n",
    "- Utilizamos estes valores encontrados e damos de input para a função objetivo real, e amostramos um novo ponto;\n",
    "- Atualizamos o modelo surrogate, incorporando o novo ponto amostrado;\n",
    "- Repetimos os últimos 3 passos, até atingirmos o critério de parada (em geral, um número pré-definido de passos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd867c8-e38d-4d68-a49f-09a92ba8da40",
   "metadata": {},
   "source": [
    "Há muitas formas possíveis para o modelo surrogate. Um método muito interessante é o que utiliza processos gaussianos. Sugiro muito a leitura [deste post interativo](https://distill.pub/2019/visual-exploration-gaussian-processes/) para conhecer um pouco mais sobre este método; e [este post](https://towardsdatascience.com/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0) para uma intuição quanto a sua aplicação como modelo surrogate da otimização bayesiana.\n",
    "\n",
    "Na nossa implementação prática, utilizaremos o método conhecido como **Tree-structured Parzen Estimator** (TPE) para a construção do modelo surrogate.\n",
    "\n",
    "Não nos preocuparemos com a matemática por trás do método. (Aos interessados, sugiro a leitura [deste artigo](https://www.diva-portal.org/smash/get/diva2:1223709/FULLTEXT01.pdf), que compara diferentes modelos surrogates e técnicas de otimização de hiperparâmetros, no contexto de redes neurais, embora as ideias sejam válidas no geral)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77446785-4fc6-426a-929d-f7b2ec620d5a",
   "metadata": {},
   "source": [
    "Basta sabermos o seguinte: o TPE precisa de um **threshold de score**:\n",
    "\n",
    "<img src=https://miro.medium.com/max/1120/1*H5pyf3G115WGJwPpg65yaQ.png width=400>\n",
    "\n",
    "Com base neste score, o método gera distribuições de probabilidade a priori, para ambos os valores de hiperparâmetros que estão acima e abaixo do threshold.\n",
    "\n",
    "Uma vez em posse destas distribuições, o método se utiliza então de um **critério de escolha** que favorece valores dos hiperparâmetros que estão do lado do threshold que nos interessa (no caso deste exemplo, abaixo do threshold), e estes valores são propostos como os próximos hiperparâmetros a serem escolhidos.\n",
    "\n",
    "E é assim que o TPE consegue \"focar nas regiões promissoras\" do espaço de hiperparâmetros. Muito legal, não é mesmo?\n",
    "\n",
    "Mas ainda resta uma pergunta: qual é exatamente este critério de escolha das regiões? **Como**, a cada iteração, os próximos valores de hiperparâmetros são propostos, com o objetivo de minimizar a função objetivo?\n",
    "\n",
    "Isto é feito de acordo com a chamada **função de seleção**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350028bd-af02-4bfd-935e-175a997e5439",
   "metadata": {},
   "source": [
    "### 2.3) Função de seleção\n",
    "\n",
    "O objetivo da função de seleção é muito simples: **determinar os valores dos hiperparâmetros que são escolhidos do modelo surrogate** a cada passo.\n",
    "\n",
    "Há vários critérios possíveis, mas o mais comum é conhecido como **Expected Improvement** (melhoria esperada), e ela é uma função do modelo surrogate. Seu uso é bem direto: **propomos novos valores de hiperparâmetros de modo que o expected improvement seja maximizado**. \n",
    "\n",
    "Podemos omitir aqui os detalhes matemáticos, o importante é lembrarmos que é o papel da função de seleção estabelecer o critério segundo o qual o modelo surrogate irá proporcionar os valores de hiperparâmetros a cada iteração.\n",
    "\n",
    "E, com isso, conseguimos, a cada iteração, propor candidatos a valores de hiperparâmetros que melhoram o modelo surrogate. O registro destes valores é muito importante, para que o teorema de Bayes entre em ação!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706124b1-72ae-44e7-9fff-9e11b8b705fe",
   "metadata": {},
   "source": [
    "### 2.4) Histórico de registros\n",
    "\n",
    "O histórico de registros, que é uma tupla com **(valores de hiperparâmetros, respectivo score)** é muitíssimo importante para que seja possível a construção de um modelo surrogate que, a cada passo, melhora a descrição probabilística da função objetivo.\n",
    "\n",
    "Isso é importante pois, quão melhor for nossa descrição da função objetivo, teremos que o passo disponibilizado pelo expected improvement irá proporcionar hiperparâmetros mais próximos do ótimo da função objetivo. \n",
    "\n",
    "E é aqui que o teorema de Bayes entra em ação: a partir de novas evidências (amostras do surrogate), atualizamos a nossa descrição da funcção objetivo com cada vez mais detalhes, e, assim, ela fica mais fácil de ser otimizada, sem precisar ser explicitamente construída!\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*RQ-pAwQ88yC904QppChGPQ.png width=500>\n",
    "\n",
    "<img src=https://miro.medium.com/max/1400/1*bSLAe1LCj3mMKfaZsQWCrw.png width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e6dc6-3c5b-4064-ac49-988160a11891",
   "metadata": {},
   "source": [
    "Agora que já conhecemos todos os ingredientes importantes, podemos dizer enunciar o passo-a-passo da otimização bayesiana:\n",
    "\n",
    "- Primeiro definimos um espaço de busca para cada um dos hiperparâmetros, impondo uma distribuição de probabilidade sobre o espaço;\n",
    "- Construímos implicitamente a função objetivo, que tem como inputs os hiperparâmetros, e como output o score a ser otimizado (que será a métrica de avaliação de interesse);\n",
    "- Construímos o modelo surrogate probabilístico da função objetivo;\n",
    "- Construímos a função de seleção, que irá determinar os próximos valores para os hiperparâmetros a serem escolhidos do modelo surrogate;\n",
    "- Atualizamos um histórico de valores de hiperparâmetros e respectivo score, que é utilizado pelo algoritmo para a atualização do modelo surrogate;\n",
    "- Repetimos o processo até o critério de parada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec18f5-2612-47b9-96e7-18ff89881e2d",
   "metadata": {},
   "source": [
    "### Em resumo, a otimização Bayesiana funciona da seguinte forma:\n",
    "\n",
    "Para cada hyperparâmetro temos uma função Surrogate que calcula o score para esse parâmetro. Essencialmente aqui, está sedo feito um ajuste de curva da função surrogate com os parâmetros e scores.\n",
    "\n",
    "Porém, essa curva não é ajustada em todos os pontos, de acordo com amostras e com o comportamento dos scores, ela define atrvés do TPE regiões que vale mais a pena realizar um ajuste mais preciso.\n",
    "\n",
    "Definindo essas \"Regiões de confiança\", a função foca em testar mais combinações associadas a essa região e abandona combinações de parâmetros distântes dessa região.\n",
    "\n",
    "O foco então é maximizar a Esperança (Expected Improvement) de todas as funções Surrogates. Como se fosse uma \"média\" de todos melhores scores obtidos pelas funções surrogates.\n",
    "\n",
    "Maximizando o Expected Improvement, obtemos os melhores scores com as funções surrogate. Estes melhores scores são obtidos nos melhores hiperparâmetros combinados. \n",
    "Ou seja, consequentemente, conseguimos obter os melhores parametros para uma função de Machine Learning otimizando uma função muito mais simples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df554166-e3e8-45e2-96c6-c13e029f3969",
   "metadata": {},
   "source": [
    "__________\n",
    "\n",
    "E é isso!\n",
    "\n",
    "Para os interessados em maiores detalhes matemáticos, recomendo fortemente [este artigo](http://proceedings.mlr.press/v28/bergstra13.pdf), e [este também](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf), que reporta resultados incríveis a favor do uso de otimização bayesiana como alternativa aos métodos tradicionais de otimização de hiperparâmetros.\n",
    "\n",
    "Agora, vamos ver o método funcionando na prática!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15990a4-97f9-4231-a889-51ba7ab31d93",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b71f61-003d-44f5-8c30-c0bb0bc6e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Começar com as importações iniciais\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9fc35-df19-46c9-b6cc-e863c85389c0",
   "metadata": {},
   "source": [
    "### 1. Vamos inicial com uma aplicação bastante simplória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258a5a01-982e-4c14-a0ab-6e8e351164d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9601f7-46b0-4c48-bfc7-dc1aa58c7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132c7fc5-296a-40ad-b58a-6b143c5573cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0402576b-2ad1-44d4-94d5-444a2e54b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecc1dc3-989c-4538-95d1-2356e857b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include = np.number).drop(columns = [\"output\"])\n",
    "y = df[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cedd599-82c5-4dd4-aeeb-69e72ae42e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazemos o split dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d726cc-1efd-4a43-8aa4-801ebfc06be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8b2898-c424-487c-a851-18681d4fa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ade8b0-44b6-4620-a10d-4b1b624ae22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos fazer uma otimização comum para o paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755243c9-9b3a-442d-990c-8e716b49ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de treino? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5b1e13-31b1-4ac1-9c25-849eda0a3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de teste? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11737e35-cb1a-40de-bdb4-0d7f9917d3ad",
   "metadata": {},
   "source": [
    "### Vamos realizar agora o processo de OTIMIZAÇÃO BAYESIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0cf6e0-9f45-4de7-9f3a-0dc2262a8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialmente fazemos os importes para isso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cddeefe8-11b3-4394-80a2-07be05b82fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, assim como temos o dicionário \"params_grid\", aqui criamos o \"hps_space\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f792ce12-0a1f-40c9-b91d-d8521376855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, precisamos criar nossa FUNÇÃO OBJETIVO:\n",
    "#    Ela recebe o \"hps_space\" como parâmetro e deve retornar que queremos MÁXIMIZAR\n",
    "\n",
    "# REPITO, MAXIMIZAR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c69237-0a11-45f8-9635-dd3266fc4cd4",
   "metadata": {},
   "source": [
    "Agora, instanciamos a classe [Trials()](http://hyperopt.github.io/hyperopt/getting-started/minimizing_functions/#the-trials-object), que é a interface que nos permitirá realizar a otimização bayesiana, e que guarada o histórico, como veremos.\n",
    "\n",
    "Note que também passamos o TPE como algoritmo para o modelo surrogate, o que é dado pelo `tpe.suggest`.\n",
    "\n",
    "Indicamos também o número máximo de passos que queremos, com o `max_evals`.\n",
    "\n",
    "A otimização em si é realizada com a chamada da função `fmin()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "457df504-b1c8-4611-ada2-590634c0b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pré-resposta da otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcfe92da-74ff-4761-8471-5055434acea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a resposta final, vem com o space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2d152d3-d563-4e49-9d55-2d7a89e68a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora podemos definir nosso modelo otimizado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7467741c-fc11-4e1f-946d-1ce24d21e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de treino? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59f33d6-a3b4-4515-9054-a3c5c1112615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de teste? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7bd3e-3afb-4aed-bcc2-89f4db24dc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688c397a-8c94-4deb-8f55-d6f1d8fe5a01",
   "metadata": {},
   "source": [
    "### Vale testar os tempos de processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a0ac968-f78f-440a-91f6-5fa43a496d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# random_gb.fit(X_train, y_train)\n",
    "\n",
    "# 884 ms ± 44.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1c313e-ebaa-4e2c-8a0e-79235dae61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit  \n",
    "\n",
    "# trials = Trials()\n",
    "\n",
    "# best_hps = fmin(funcao_objetivo, # função objetivo\n",
    "#                 space=hps_space, # o espaço de parâmetros\n",
    "#                 algo=tpe.suggest, # o tpe para o surrogate\n",
    "#                 trials=trials, # trials para registrar o histórico\n",
    "#                 rstate=np.random.default_rng(42), # semente randomica \n",
    "#                 max_evals=10) # número máximo de avaliações\n",
    "# best_hps = space_eval(hps_space, best_hps)\n",
    "\n",
    "#1.1 s ± 21.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a80656-44eb-463a-b5ba-5cc30328d18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a907b19-3e0a-4c1b-a54a-bcd382d2dbc3",
   "metadata": {},
   "source": [
    "### E se eu quisesse entender o que meu modelo está fazendo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb28d4-222c-4ccb-aaf8-a76eb9589ddf",
   "metadata": {},
   "source": [
    "#### Para 1 dado em específico: LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5738ada2-20e3-490d-94c5-ecefe199a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instale o lime\n",
    "# importe o lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e57a22a9-6ddb-4719-a6c8-68750873736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, precisamos de coisas do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "135ed420-28b2-4282-a1fc-f57dfa72d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resgatamos o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47c9555a-4c04-4113-aaa1-89eadd926a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resgatamos os nomes dos features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "590ca6ae-2734-411e-968c-e8c34e276c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resgatamos as classes que ele treinou "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb2f4380-9166-4024-8063-d6b487429e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora \"treinamos\" o lime_tabular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65766866-b7ab-4cb4-babf-27334866f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, escolha 1 dado específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09abf140-9b28-485f-8ce6-ca347babbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agpra pedimos a explicacao de um dado em específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b84b1cd3-94fd-429d-9eeb-d6557a477b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E podemos observar essa explicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be6282cd-0a65-48b1-9b4e-54fbfc14463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Até mesmo como forma de lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5f532-ada4-4b88-a2a3-fd73b8086907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c43fd724-c9d1-4fcf-9604-690323a0ba82",
   "metadata": {},
   "source": [
    "#### E se eu quiser saber como as variáveis estão influenciando no modelo em geral? SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b91f598-9e16-41cd-bcc6-ce5507dcea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intale o shap\n",
    "# importe o shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be0c8393-ba84-4f26-afbf-874cd147d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passamos o modelo para o expolicador do shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c8c51f4-7c88-485e-9e8d-a9277daf92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resgatamos os valores shap a partir dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55816471-7349-489b-84d1-ffb3bf08d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos visualizar a importância de diversas formas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3888d11-7823-4f34-a719-32cda47ad589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85506db8-2e2a-4358-92c1-38cefdaa1682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c03a9a5-bccf-411e-9a9c-d2729991f9dc",
   "metadata": {},
   "source": [
    "### Agora vamos tentar com um pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd6c9c5e-6c47-43fa-97b4-736dc559b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e9deaea-7dac-4639-a993-5802e6d34731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39fbf52f-17d0-4aa2-80b9-d0872b162267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos o pipeline para features numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "765a113e-20de-4482-8c55-1928b7b93bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvamos os nomes para depois\n",
    "features_num = X_train.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "433adb89-19d9-46b5-86a8-3256d095eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos o pipeline para features categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a7477f4-3934-4b4a-86db-e4e39848f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também salvamos os nomes para depois\n",
    "features_cat = X_train.select_dtypes(exclude=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2d1814c-580e-45c2-8379-c48674fdc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o pipeline que processará por completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8415a46-9f70-4cf8-8de2-fadcfbcf9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, se vamos implementar a OTMIZAÇÃO BAYESIANA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e75c6b8e-bd04-45b8-8755-3d054f1bf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denifimos o espaço de parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df7e3192-870d-473a-867f-9dcc43fb4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos a função objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb9f4e5d-1b47-40f5-998a-66a3e8307c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizamos como essa função deverá ser minimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e08eb449-33da-45a3-8403-101edcc12cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta inicial antes de otimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e869e8f4-1f82-4772-965c-f5b9b859cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta final considerando nossos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0e32a08-e545-4cb2-aa17-54c77f539a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos o modelo com os novos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72d7e299-517e-48da-a371-00e35a25539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de treino? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9aa60ac0-c05f-4f77-9b70-816907e3d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como foi nos dados de teste? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4282c-3a27-417f-b1b8-f1d826ed564a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b688f8-0b4d-4f6e-84f2-4bd4ed3ca190",
   "metadata": {},
   "source": [
    "## Exercício 1:\n",
    "\n",
    "Crie um modelo para otmização Bayesiana assim como foi feito, porém utilize o dataset \"german_credit_risk\" e OUTRO MODELO:\n",
    "\n",
    "    - LogisticRegression;\n",
    "    - DecisioTreeClassifier;\n",
    "    - XGBoostClassifier;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef7c82-c77e-46b4-8995-414783f0dd07",
   "metadata": {},
   "source": [
    "## Exercício 2: \n",
    "\n",
    "Refaça a implementação realizada em aula, porém utilizando a biblioteca [scikit-optimize](https://towardsdatascience.com/hyperparameter-optimization-with-scikit-learn-scikit-opt-and-keras-f13367f3e796)\n",
    "\n",
    "(O link não é da documentação, mas sim um exemplo de implementação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8307473-6252-4696-b85a-a3a240efbd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1f049-95a8-4127-bb5e-c84a8f60e085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
